{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the code from https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "* Set up tensorboard for all functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train a simple deep CNN on the CIFAR10 small images dataset.\n",
    "It gets to 75% validation accuracy in 25 epochs, and 79% after 50 epochs.\n",
    "(it's still underfitting at that point, though).\n",
    "'''\n",
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os\n",
    "from keras.callbacks import CSVLogger, TensorBoard\n",
    "from keras.layers.noise import AlphaDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 1\n",
    "data_augmentation = False\n",
    "num_predictions = 20\n",
    "experiments = 3\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "activations_orig = ['relu']\n",
    "metrics = {\n",
    "    'orig_relu': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_sigmoid': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_tanh': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_linear': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_elu': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_selu_rmsp': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_selu_adam': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'orig_selu_sgd': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'rand_all_last_dense': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'rand_all_all': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'rand_sig_last_dense': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'rand_sig_all': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'rand_lin_last_dense': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    },\n",
    "    'rand_lin_all': {\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'avg_val_loss': 0,\n",
    "        'avg_val_acc': 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data, shuffled and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Training for  relu\n",
      "Experiment 1\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 354s 7ms/step - loss: 1.9576 - acc: 0.2833 - val_loss: 1.7174 - val_acc: 0.3889\n",
      "Saved trained model at c:\\workspace\\activation_functions\\tests\\cifar_10\\saved_models\\cifar10_orig_relu_00.h5 \n",
      "Test loss: 1.71738571148\n",
      "Test accuracy: 0.3889\n"
     ]
    }
   ],
   "source": [
    "activation = activations_orig[0]\n",
    "model_name = 'cifar10_orig_' + activation + '_'\n",
    "\n",
    "experiment = 0\n",
    "keras.backend.clear_session()\n",
    "print('-'*30)\n",
    "print('Training for ', activation)\n",
    "print('Experiment', experiment+1)\n",
    "\n",
    "%run ./train.py orig relu 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 311s 6ms/step - loss: 1.9297 - acc: 0.2925 - val_loss: 1.6590 - val_acc: 0.4100\n",
      "Saved trained model at c:\\workspace\\activation_functions\\tests\\cifar_10\\saved_models\\cifar10_orig_relu_11.h5 \n",
      "Test loss: 1.65896893635\n",
      "Test accuracy: 0.41\n"
     ]
    }
   ],
   "source": [
    "%run ./train.py orig relu 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Training for  relu\n",
      "Experiment 3\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 346s 7ms/step - loss: 1.9737 - acc: 0.2750 - val_loss: 1.7257 - val_acc: 0.3861\n",
      "Saved trained model at c:\\workspace\\activation_functions\\tests\\cifar_10\\saved_models\\cifar10_orig_relu_2.h5 \n",
      "Test loss: 1.72566213017\n",
      "Test accuracy: 0.3861\n",
      "Average Test loss after 3 experiments: 1.725662\n",
      "Average Test accuracy after 3 experiments: 0.386100\n"
     ]
    }
   ],
   "source": [
    "activation = activations_orig[0]\n",
    "model_name = 'cifar10_orig_' + activation + '_'\n",
    "\n",
    "experiment = 2\n",
    "keras.backend.clear_session()\n",
    "print('-'*30)\n",
    "print('Training for ', activation)\n",
    "print('Experiment', experiment+1)\n",
    "\n",
    "model = Sequential()\n",
    "# inputs = Input(shape=(32,32,3))\n",
    "# x = Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:])(inputs)\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Conv2D(32, (3, 3))(x)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# x = Dropout(0.25)(x)\n",
    "model.add(Dropout(0.25))\n",
    "# x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Conv2D(64, (3, 3))(x)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# x = Dropout(0.25)(x)\n",
    "model.add(Dropout(0.25))\n",
    "# x = Flatten()(x)\n",
    "model.add(Flatten())\n",
    "# x = Dense(512)(x)\n",
    "model.add(Dense(512))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Dropout(0.5)(x)\n",
    "model.add(Dropout(0.5))\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "csv_logger = CSVLogger('../logs/cifar_10/orig_' + activation + '_log_%d.csv' % experiment, append=True, separator=';')\n",
    "tb = TensorBoard(log_dir='./tb_logs/' + model_name + str(experiment), histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "         verbose=1, callbacks=[csv_logger, tb])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name + str(experiment) + \".h5\")\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "metrics['orig_' + activation]['val_loss'].append(scores[0])\n",
    "metrics['orig_' + activation]['val_acc'].append(scores[1])\n",
    "\n",
    "metrics['orig_' + activation]['avg_val_loss'] = sum(metrics['orig_' + activation]['val_loss']) / len(metrics['orig_' + activation]['val_loss'])\n",
    "metrics['orig_' + activation]['avg_val_acc'] = sum(metrics['orig_' + activation]['val_acc']) / len(metrics['orig_' + activation]['val_acc'])\n",
    "\n",
    "print('Average Test loss after %d experiments: %f' % (experiment+1, metrics['orig_' + activation]['avg_val_loss']))\n",
    "print('Average Test accuracy after %d experiments: %f' % (experiment+1, metrics['orig_' + activation]['avg_val_acc'] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Training for  relu\n",
      "Experiment 4\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 341s 7ms/step - loss: 2.1845 - acc: 0.1943 - val_loss: 2.0609 - val_acc: 0.2535\n",
      "Saved trained model at c:\\workspace\\activation_functions\\tests\\cifar_10\\saved_models\\cifar10_orig_relu_3.h5 \n",
      "Test loss: 2.0609329977\n",
      "Test accuracy: 0.2535\n",
      "Average Test loss after 4 experiments: 1.893298\n",
      "Average Test accuracy after 4 experiments: 0.319800\n"
     ]
    }
   ],
   "source": [
    "activation = activations_orig[0]\n",
    "model_name = 'cifar10_orig_' + activation + '_'\n",
    "\n",
    "experiment = 3\n",
    "keras.backend.clear_session()\n",
    "print('-'*30)\n",
    "print('Training for ', activation)\n",
    "print('Experiment', experiment+1)\n",
    "\n",
    "model = Sequential()\n",
    "# inputs = Input(shape=(32,32,3))\n",
    "# x = Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:])(inputs)\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Conv2D(32, (3, 3))(x)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# x = Dropout(0.25)(x)\n",
    "model.add(Dropout(0.25))\n",
    "# x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Conv2D(64, (3, 3))(x)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# x = Dropout(0.25)(x)\n",
    "model.add(Dropout(0.25))\n",
    "# x = Flatten()(x)\n",
    "model.add(Flatten())\n",
    "# x = Dense(512)(x)\n",
    "model.add(Dense(512))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Dropout(0.5)(x)\n",
    "model.add(Dropout(0.5))\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "csv_logger = CSVLogger('../logs/cifar_10/orig_' + activation + '_log_%d.csv' % experiment, append=True, separator=';')\n",
    "tb = TensorBoard(log_dir='./tb_logs/' + model_name + str(experiment), histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "         verbose=1, callbacks=[csv_logger, tb])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name + str(experiment) + \".h5\")\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "metrics['orig_' + activation]['val_loss'].append(scores[0])\n",
    "metrics['orig_' + activation]['val_acc'].append(scores[1])\n",
    "\n",
    "metrics['orig_' + activation]['avg_val_loss'] = sum(metrics['orig_' + activation]['val_loss']) / len(metrics['orig_' + activation]['val_loss'])\n",
    "metrics['orig_' + activation]['avg_val_acc'] = sum(metrics['orig_' + activation]['val_acc']) / len(metrics['orig_' + activation]['val_acc'])\n",
    "\n",
    "print('Average Test loss after %d experiments: %f' % (experiment+1, metrics['orig_' + activation]['avg_val_loss']))\n",
    "print('Average Test accuracy after %d experiments: %f' % (experiment+1, metrics['orig_' + activation]['avg_val_acc'] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Training for  relu\n",
      "Experiment 5\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 328s 7ms/step - loss: 2.3027 - acc: 0.0954 - val_loss: 2.3026 - val_acc: 0.1000\n",
      "Saved trained model at c:\\workspace\\activation_functions\\tests\\cifar_10\\saved_models\\cifar10_orig_relu_4.h5 \n",
      "Test loss: 2.3025854847\n",
      "Test accuracy: 0.1\n",
      "Average Test loss after 5 experiments: 2.029727\n",
      "Average Test accuracy after 5 experiments: 0.246533\n"
     ]
    }
   ],
   "source": [
    "activation = activations_orig[0]\n",
    "model_name = 'cifar10_orig_' + activation + '_'\n",
    "\n",
    "experiment = 4\n",
    "keras.backend.clear_session()\n",
    "print('-'*30)\n",
    "print('Training for ', activation)\n",
    "print('Experiment', experiment+1)\n",
    "\n",
    "model = Sequential()\n",
    "# inputs = Input(shape=(32,32,3))\n",
    "# x = Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:])(inputs)\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Conv2D(32, (3, 3))(x)\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# x = Dropout(0.25)(x)\n",
    "model.add(Dropout(0.25))\n",
    "# x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Conv2D(64, (3, 3))(x)\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# x = Dropout(0.25)(x)\n",
    "model.add(Dropout(0.25))\n",
    "# x = Flatten()(x)\n",
    "model.add(Flatten())\n",
    "# x = Dense(512)(x)\n",
    "model.add(Dense(512))\n",
    "# x = Activation(activation)(x)\n",
    "model.add(Activation('relu'))\n",
    "# x = Dropout(0.5)(x)\n",
    "model.add(Dropout(0.5))\n",
    "# predictions = Dense(num_classes, activation='softmax')(x)\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "csv_logger = CSVLogger('../logs/cifar_10/orig_' + activation + '_log_%d.csv' % experiment, append=True, separator=';')\n",
    "tb = TensorBoard(log_dir='./tb_logs/' + model_name + str(experiment), histogram_freq=0, batch_size=batch_size, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test),\n",
    "         verbose=1, callbacks=[csv_logger, tb])\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name + str(experiment) + \".h5\")\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=2)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "metrics['orig_' + activation]['val_loss'].append(scores[0])\n",
    "metrics['orig_' + activation]['val_acc'].append(scores[1])\n",
    "\n",
    "metrics['orig_' + activation]['avg_val_loss'] = sum(metrics['orig_' + activation]['val_loss']) / len(metrics['orig_' + activation]['val_loss'])\n",
    "metrics['orig_' + activation]['avg_val_acc'] = sum(metrics['orig_' + activation]['val_acc']) / len(metrics['orig_' + activation]['val_acc'])\n",
    "\n",
    "print('Average Test loss after %d experiments: %f' % (experiment+1, metrics['orig_' + activation]['avg_val_loss']))\n",
    "print('Average Test accuracy after %d experiments: %f' % (experiment+1, metrics['orig_' + activation]['avg_val_acc'] ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
