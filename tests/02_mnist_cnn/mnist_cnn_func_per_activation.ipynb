{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "from keras.layers.noise import AlphaDropout\n",
    "import keras.activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 30\n",
    "units = 64\n",
    "experiments = 1\n",
    "start = 0\n",
    "# activations = ['sigmoid', 'tanh', 'relu', 'linear', 'elu', 'softplus', 'softsign', 'hard_sigmoid', 'LeakyReLU', 'ThresholdedReLU']\n",
    "activations = ['hard_sigmoid']\n",
    "# PReLU is not used, since it does not currently support variable inputs\n",
    "# optimizers = ['rmsp', 'adam', 'sgd', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']\n",
    "optimizers = ['Nadam']\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train per each activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for activation hard_sigmoid with optimizer Nadam\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 2.3695 - acc: 0.1018 - val_loss: 2.3098 - val_acc: 0.1032\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 274s 5ms/step - loss: 2.3125 - acc: 0.1038 - val_loss: 2.3078 - val_acc: 0.0958\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 324s 5ms/step - loss: 2.3129 - acc: 0.1016 - val_loss: 2.3027 - val_acc: 0.1135\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 339s 6ms/step - loss: 2.3115 - acc: 0.1015 - val_loss: 2.3037 - val_acc: 0.0982\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 359s 6ms/step - loss: 2.3124 - acc: 0.1036 - val_loss: 2.3076 - val_acc: 0.1010\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 341s 6ms/step - loss: 2.3119 - acc: 0.1026 - val_loss: 2.3069 - val_acc: 0.1032\n",
      "Epoch 7/30\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 2.3122 - acc: 0.1037\n",
      "Epoch 00007: reducing learning rate to 0.0004000000189989805.\n",
      "60000/60000 [==============================] - 351s 6ms/step - loss: 2.3122 - acc: 0.1037 - val_loss: 2.3061 - val_acc: 0.1135\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 355s 6ms/step - loss: 2.3060 - acc: 0.1070 - val_loss: 2.3022 - val_acc: 0.1135\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 362s 6ms/step - loss: 2.3042 - acc: 0.1071 - val_loss: 2.3020 - val_acc: 0.1135\n",
      "Epoch 10/30\n",
      "13056/60000 [=====>........................] - ETA: 4:19 - loss: 2.3041 - acc: 0.1045"
     ]
    }
   ],
   "source": [
    "for act in activations:\n",
    "    for opt in optimizers:\n",
    "        print(\"\\nTraining for activation \" + act + \" with optimizer \" + opt)\n",
    "\n",
    "        # Selecting activation function\n",
    "        if act == 'sigmoid':\n",
    "            activation = Activation(keras.activations.sigmoid)\n",
    "        elif act == 'tanh':\n",
    "            activation = Activation(keras.activations.tanh)\n",
    "        elif act == 'relu':\n",
    "            activation = Activation(keras.activations.relu)\n",
    "        elif act == 'linear':\n",
    "            activation = Activation(keras.activations.linear)\n",
    "        elif act == 'elu':\n",
    "            activation = Activation(keras.activations.elu)\n",
    "        elif act == 'softplus':\n",
    "            activation = Activation(keras.activations.softplus)\n",
    "        elif act == 'softsign':\n",
    "            activation = Activation(keras.activations.softsign)\n",
    "        elif act == 'hard_sigmoid':\n",
    "            activation = Activation(keras.activations.hard_sigmoid)\n",
    "        elif act == 'LeakyReLU':\n",
    "            activation = keras.layers.advanced_activations.LeakyReLU()\n",
    "        elif act == 'PReLU':\n",
    "            activation = keras.layers.advanced_activations.PReLU()\n",
    "        elif act == 'ThresholdedReLU':\n",
    "            activation = keras.layers.advanced_activations.ThresholdedReLU(theta=0.7)\n",
    "            \n",
    "\n",
    "        if opt == 'rmsp':\n",
    "            optimizer = keras.optimizers.rmsprop()                \n",
    "        elif opt == 'adam':\n",
    "            optimizer = keras.optimizers.Adam()\n",
    "        elif opt == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD()\n",
    "        elif opt == 'Adagrad':\n",
    "            optimizer = keras.optimizers.Adagrad()\n",
    "        elif opt == 'Adadelta':\n",
    "            optimizer = keras.optimizers.Adadelta()\n",
    "        elif opt == 'Adamax':\n",
    "            optimizer = keras.optimizers.Adamax()\n",
    "        elif opt == 'Nadam':\n",
    "            optimizer = keras.optimizers.Nadam()\n",
    "        \n",
    "        for i in range(experiments):\n",
    "            model_name = 'mnist_cnn_' + act + \"_\" + opt + '_' + str(i + start)\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                             input_shape=input_shape))\n",
    "            \n",
    "            model.add(activation)\n",
    "            model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "            model.add(activation)\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
    "            model.add(Dropout(0.25))\n",
    "            model.add(Flatten())\n",
    "            model.add(Dense(128))\n",
    "            model.add(activation)\n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "            \n",
    "            print('-'*30)\n",
    "            print('Experiment', i)\n",
    "\n",
    "            csv_logger = CSVLogger('./logs/%s_%d.csv' % (model_name, units), append=False, separator=';')\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=2, min_lr=0)\n",
    "#             tb = TensorBoard(log_dir='./tb_logs/' + model_name + '_' + str(units), histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "            history = model.fit(x_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "            if not os.path.isdir(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            model_path = os.path.join(save_dir, model_name + \".h5\")\n",
    "#             model.save(model_path)\n",
    "\n",
    "            score = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeLU\n",
    "This one has special requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activation SeLU with optimizer rmsp\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.2262 - acc: 0.9348 - val_loss: 0.0938 - val_acc: 0.9806\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0951 - acc: 0.9743 - val_loss: 0.1054 - val_acc: 0.9822\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0756 - acc: 0.9797 - val_loss: 0.1003 - val_acc: 0.9850\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0680 - acc: 0.9825 - val_loss: 0.0904 - val_acc: 0.9862\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0634 - acc: 0.9840 - val_loss: 0.1203 - val_acc: 0.9823\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0579 - acc: 0.9862 - val_loss: 0.1092 - val_acc: 0.9859\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0563 - acc: 0.9867 - val_loss: 0.1075 - val_acc: 0.9872\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0507 - acc: 0.9873 - val_loss: 0.1135 - val_acc: 0.9870\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0439 - acc: 0.9896 - val_loss: 0.1111 - val_acc: 0.9867\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0477 - acc: 0.9892 - val_loss: 0.1016 - val_acc: 0.9891\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.0396 - acc: 0.9908 - val_loss: 0.0936 - val_acc: 0.9900\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0395 - acc: 0.9911 - val_loss: 0.1017 - val_acc: 0.9885\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0350 - acc: 0.9917 - val_loss: 0.1190 - val_acc: 0.9878\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0355 - acc: 0.9921 - val_loss: 0.1120 - val_acc: 0.9881\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 290s 5ms/step - loss: 0.0378 - acc: 0.9919 - val_loss: 0.1327 - val_acc: 0.9876\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0352 - acc: 0.9923 - val_loss: 0.0981 - val_acc: 0.9899\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0341 - acc: 0.9927 - val_loss: 0.1049 - val_acc: 0.9886\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0216 - acc: 0.9951 - val_loss: 0.0942 - val_acc: 0.9900\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0131 - acc: 0.9967 - val_loss: 0.0958 - val_acc: 0.9907\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0134 - acc: 0.9966 - val_loss: 0.0915 - val_acc: 0.9910\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0132 - acc: 0.9969 - val_loss: 0.0883 - val_acc: 0.9909\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0120 - acc: 0.9972 - val_loss: 0.0873 - val_acc: 0.9909\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0094 - acc: 0.9979 - val_loss: 0.0953 - val_acc: 0.9907\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0109 - acc: 0.9978 - val_loss: 0.0968 - val_acc: 0.9901\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0103 - acc: 0.9973 - val_loss: 0.0879 - val_acc: 0.9915\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0097 - acc: 0.9977 - val_loss: 0.0976 - val_acc: 0.9911\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0895 - val_acc: 0.9907\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0102 - acc: 0.9976 - val_loss: 0.0929 - val_acc: 0.9907\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0091 - acc: 0.9976 - val_loss: 0.1026 - val_acc: 0.9903\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0948 - val_acc: 0.9906\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0100 - acc: 0.9976 - val_loss: 0.0956 - val_acc: 0.9900\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.1023 - val_acc: 0.9899\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0065 - acc: 0.9983 - val_loss: 0.0969 - val_acc: 0.9908\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0078 - acc: 0.9984 - val_loss: 0.0922 - val_acc: 0.9908\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0073 - acc: 0.9982 - val_loss: 0.0938 - val_acc: 0.9911\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0949 - val_acc: 0.9910\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0064 - acc: 0.9985 - val_loss: 0.0932 - val_acc: 0.9907\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0068 - acc: 0.9984 - val_loss: 0.0905 - val_acc: 0.9909\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0914 - val_acc: 0.9911\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0915 - val_acc: 0.9911\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0065 - acc: 0.9985 - val_loss: 0.0913 - val_acc: 0.9911\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0915 - val_acc: 0.9909\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0060 - acc: 0.9986 - val_loss: 0.0913 - val_acc: 0.9910\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0910 - val_acc: 0.9911\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0911 - val_acc: 0.9911\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0910 - val_acc: 0.9911\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0908 - val_acc: 0.9911\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0068 - acc: 0.9986 - val_loss: 0.0908 - val_acc: 0.9911\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0070 - acc: 0.9986 - val_loss: 0.0908 - val_acc: 0.9911\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0904 - val_acc: 0.9911\n",
      "Test loss: 0.0904386542887\n",
      "Test accuracy: 0.9911\n",
      "Training for activation SeLU with optimizer adam\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.2018 - acc: 0.9377 - val_loss: 0.0739 - val_acc: 0.9806\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.0846 - acc: 0.9753 - val_loss: 0.0954 - val_acc: 0.9815\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0660 - acc: 0.9801 - val_loss: 0.0829 - val_acc: 0.9848\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0561 - acc: 0.9831 - val_loss: 0.0775 - val_acc: 0.9865\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0510 - acc: 0.9850 - val_loss: 0.0773 - val_acc: 0.9873\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.0457 - acc: 0.9867 - val_loss: 0.0973 - val_acc: 0.9846\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0455 - acc: 0.9873 - val_loss: 0.0773 - val_acc: 0.9884\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0408 - acc: 0.9880 - val_loss: 0.0898 - val_acc: 0.9874\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0373 - acc: 0.9898 - val_loss: 0.0803 - val_acc: 0.9873\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0374 - acc: 0.9904 - val_loss: 0.0881 - val_acc: 0.9877\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 316s 5ms/step - loss: 0.0356 - acc: 0.9901 - val_loss: 0.1006 - val_acc: 0.9871\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0335 - acc: 0.9906 - val_loss: 0.0931 - val_acc: 0.9878\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0369 - acc: 0.9905 - val_loss: 0.0792 - val_acc: 0.9880\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0177 - acc: 0.9949 - val_loss: 0.0739 - val_acc: 0.9899\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0108 - acc: 0.9964 - val_loss: 0.0737 - val_acc: 0.9904\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0747 - val_acc: 0.9908\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.0076 - acc: 0.9976 - val_loss: 0.0690 - val_acc: 0.9910\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 0.0743 - val_acc: 0.9906\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0063 - acc: 0.9977 - val_loss: 0.0730 - val_acc: 0.9916\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 308s 5ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0762 - val_acc: 0.9919\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3451s 58ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0727 - val_acc: 0.9910\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 345s 6ms/step - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0763 - val_acc: 0.9911\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0721 - val_acc: 0.9917\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0814 - val_acc: 0.9912\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 347s 6ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0804 - val_acc: 0.9907\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 336s 6ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0825 - val_acc: 0.9908\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 327s 5ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0752 - val_acc: 0.9918\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.0043 - acc: 0.9986 - val_loss: 0.0781 - val_acc: 0.9912\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 331s 6ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0793 - val_acc: 0.9917\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 331s 6ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0755 - val_acc: 0.9916\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 350s 6ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0770 - val_acc: 0.9918\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 347s 6ms/step - loss: 0.0028 - acc: 0.9990 - val_loss: 0.0799 - val_acc: 0.9915\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 344s 6ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0789 - val_acc: 0.9914\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 344s 6ms/step - loss: 0.0026 - acc: 0.9991 - val_loss: 0.0782 - val_acc: 0.9916\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 337s 6ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0791 - val_acc: 0.9914\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 326s 5ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0779 - val_acc: 0.9914\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 330s 6ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0780 - val_acc: 0.9916\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0792 - val_acc: 0.9916\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 330s 5ms/step - loss: 0.0030 - acc: 0.9991 - val_loss: 0.0788 - val_acc: 0.9914\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 347s 6ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0788 - val_acc: 0.9915\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 329s 5ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0790 - val_acc: 0.9915\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 327s 5ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0787 - val_acc: 0.9915\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0788 - val_acc: 0.9915\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0786 - val_acc: 0.9915\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 332s 6ms/step - loss: 0.0029 - acc: 0.9990 - val_loss: 0.0787 - val_acc: 0.9915\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0786 - val_acc: 0.9915\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 330s 6ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0786 - val_acc: 0.9915\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0786 - val_acc: 0.9915\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 309s 5ms/step - loss: 0.0022 - acc: 0.9993 - val_loss: 0.0787 - val_acc: 0.9915\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0020 - acc: 0.9993 - val_loss: 0.0787 - val_acc: 0.9915\n",
      "Test loss: 0.0786700591119\n",
      "Test accuracy: 0.9915\n",
      "Training for activation SeLU with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 332s 6ms/step - loss: 0.4848 - acc: 0.8471 - val_loss: 0.2267 - val_acc: 0.9403\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 307s 5ms/step - loss: 0.2397 - acc: 0.9287 - val_loss: 0.1582 - val_acc: 0.9588\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 277s 5ms/step - loss: 0.1827 - acc: 0.9451 - val_loss: 0.1330 - val_acc: 0.9656\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 291s 5ms/step - loss: 0.1537 - acc: 0.9541 - val_loss: 0.1122 - val_acc: 0.9713\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.1340 - acc: 0.9599 - val_loss: 0.1071 - val_acc: 0.9712\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 275s 5ms/step - loss: 0.1149 - acc: 0.9654 - val_loss: 0.0917 - val_acc: 0.9766\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 277s 5ms/step - loss: 0.1064 - acc: 0.9679 - val_loss: 0.0874 - val_acc: 0.9770\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0965 - acc: 0.9710 - val_loss: 0.0791 - val_acc: 0.9805\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0874 - acc: 0.9730 - val_loss: 0.0739 - val_acc: 0.9808\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 277s 5ms/step - loss: 0.0812 - acc: 0.9756 - val_loss: 0.0721 - val_acc: 0.9819\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0754 - acc: 0.9768 - val_loss: 0.0679 - val_acc: 0.9834\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0692 - acc: 0.9789 - val_loss: 0.0645 - val_acc: 0.9831\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 313s 5ms/step - loss: 0.0652 - acc: 0.9797 - val_loss: 0.0603 - val_acc: 0.9851\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 310s 5ms/step - loss: 0.0601 - acc: 0.9816 - val_loss: 0.0624 - val_acc: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 310s 5ms/step - loss: 0.0578 - acc: 0.9823 - val_loss: 0.0594 - val_acc: 0.9855\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 315s 5ms/step - loss: 0.0558 - acc: 0.9831 - val_loss: 0.0562 - val_acc: 0.9856\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 309s 5ms/step - loss: 0.0526 - acc: 0.9840 - val_loss: 0.0546 - val_acc: 0.9870\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0484 - acc: 0.9849 - val_loss: 0.0602 - val_acc: 0.9862\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 315s 5ms/step - loss: 0.0463 - acc: 0.9849 - val_loss: 0.0563 - val_acc: 0.9868\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 320s 5ms/step - loss: 0.0456 - acc: 0.9859 - val_loss: 0.0555 - val_acc: 0.9864\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 319s 5ms/step - loss: 0.0437 - acc: 0.9862 - val_loss: 0.0513 - val_acc: 0.9873\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0409 - acc: 0.9872 - val_loss: 0.0508 - val_acc: 0.9873\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0399 - acc: 0.9875 - val_loss: 0.0514 - val_acc: 0.9873\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0382 - acc: 0.9878 - val_loss: 0.0511 - val_acc: 0.9878\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 300s 5ms/step - loss: 0.0372 - acc: 0.9879 - val_loss: 0.0520 - val_acc: 0.9872\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 276s 5ms/step - loss: 0.0345 - acc: 0.9893 - val_loss: 0.0480 - val_acc: 0.9885\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 307s 5ms/step - loss: 0.0324 - acc: 0.9899 - val_loss: 0.0514 - val_acc: 0.9881\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 323s 5ms/step - loss: 0.0324 - acc: 0.9902 - val_loss: 0.0561 - val_acc: 0.9877\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 331s 6ms/step - loss: 0.0314 - acc: 0.9898 - val_loss: 0.0528 - val_acc: 0.9886\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 328s 5ms/step - loss: 0.0306 - acc: 0.9902 - val_loss: 0.0527 - val_acc: 0.9876\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 325s 5ms/step - loss: 0.0292 - acc: 0.9911 - val_loss: 0.0552 - val_acc: 0.9881\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 317s 5ms/step - loss: 0.0288 - acc: 0.9910 - val_loss: 0.0486 - val_acc: 0.9893\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0273 - acc: 0.9909 - val_loss: 0.0479 - val_acc: 0.9893\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 315s 5ms/step - loss: 0.0269 - acc: 0.9913 - val_loss: 0.0524 - val_acc: 0.9886\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 314s 5ms/step - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0489 - val_acc: 0.9899\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 307s 5ms/step - loss: 0.0241 - acc: 0.9922 - val_loss: 0.0486 - val_acc: 0.9895\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 312s 5ms/step - loss: 0.0250 - acc: 0.9919 - val_loss: 0.0500 - val_acc: 0.9895\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 338s 6ms/step - loss: 0.0229 - acc: 0.9927 - val_loss: 0.0480 - val_acc: 0.9899\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 318s 5ms/step - loss: 0.0231 - acc: 0.9924 - val_loss: 0.0505 - val_acc: 0.9899\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0225 - acc: 0.9932 - val_loss: 0.0498 - val_acc: 0.9892\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0219 - acc: 0.9929 - val_loss: 0.0487 - val_acc: 0.9894\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0189 - acc: 0.9943 - val_loss: 0.0484 - val_acc: 0.9898\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 298s 5ms/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0472 - val_acc: 0.9899\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 319s 5ms/step - loss: 0.0187 - acc: 0.9937 - val_loss: 0.0480 - val_acc: 0.9899\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 315s 5ms/step - loss: 0.0186 - acc: 0.9944 - val_loss: 0.0482 - val_acc: 0.9898\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 320s 5ms/step - loss: 0.0185 - acc: 0.9943 - val_loss: 0.0483 - val_acc: 0.9898\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 316s 5ms/step - loss: 0.0186 - acc: 0.9938 - val_loss: 0.0484 - val_acc: 0.9897\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 312s 5ms/step - loss: 0.0181 - acc: 0.9941 - val_loss: 0.0483 - val_acc: 0.9899\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 348s 6ms/step - loss: 0.0174 - acc: 0.9943 - val_loss: 0.0484 - val_acc: 0.9899\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 0.0183 - acc: 0.9942 - val_loss: 0.0480 - val_acc: 0.9899\n",
      "Test loss: 0.0479766140209\n",
      "Test accuracy: 0.9899\n",
      "Training for activation SeLU with optimizer Adagrad\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 339s 6ms/step - loss: 0.2729 - acc: 0.9302 - val_loss: 0.0784 - val_acc: 0.9806\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 328s 5ms/step - loss: 0.0872 - acc: 0.9731 - val_loss: 0.0621 - val_acc: 0.9854\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 321s 5ms/step - loss: 0.0631 - acc: 0.9804 - val_loss: 0.0533 - val_acc: 0.9873\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 0.0529 - acc: 0.9837 - val_loss: 0.0480 - val_acc: 0.9884\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 322s 5ms/step - loss: 0.0434 - acc: 0.9857 - val_loss: 0.0493 - val_acc: 0.9882\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 324s 5ms/step - loss: 0.0376 - acc: 0.9884 - val_loss: 0.0451 - val_acc: 0.9898\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 331s 6ms/step - loss: 0.0340 - acc: 0.9893 - val_loss: 0.0472 - val_acc: 0.9893\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 340s 6ms/step - loss: 0.0299 - acc: 0.9901 - val_loss: 0.0481 - val_acc: 0.9898\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0266 - acc: 0.9913 - val_loss: 0.0461 - val_acc: 0.9910\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 329s 5ms/step - loss: 0.0236 - acc: 0.9926 - val_loss: 0.0425 - val_acc: 0.9908\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 327s 5ms/step - loss: 0.0220 - acc: 0.9927 - val_loss: 0.0499 - val_acc: 0.9899\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 330s 6ms/step - loss: 0.0211 - acc: 0.9930 - val_loss: 0.0458 - val_acc: 0.9911\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 331s 6ms/step - loss: 0.0202 - acc: 0.9934 - val_loss: 0.0467 - val_acc: 0.9915\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 328s 5ms/step - loss: 0.0175 - acc: 0.9944 - val_loss: 0.0510 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 348s 6ms/step - loss: 0.0165 - acc: 0.9944 - val_loss: 0.0473 - val_acc: 0.9911\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 317s 5ms/step - loss: 0.0145 - acc: 0.9951 - val_loss: 0.0447 - val_acc: 0.9910\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 284s 5ms/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0457 - val_acc: 0.9911\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 310s 5ms/step - loss: 0.0136 - acc: 0.9958 - val_loss: 0.0498 - val_acc: 0.9911\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0482 - val_acc: 0.9908\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 310s 5ms/step - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0459 - val_acc: 0.9913\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 316s 5ms/step - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0457 - val_acc: 0.9907\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 337s 6ms/step - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0469 - val_acc: 0.9907\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 337s 6ms/step - loss: 0.0107 - acc: 0.9966 - val_loss: 0.0482 - val_acc: 0.9909\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 307s 5ms/step - loss: 0.0101 - acc: 0.9967 - val_loss: 0.0479 - val_acc: 0.9910\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0095 - acc: 0.9971 - val_loss: 0.0483 - val_acc: 0.9909\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0494 - val_acc: 0.9909\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 288s 5ms/step - loss: 0.0099 - acc: 0.9969 - val_loss: 0.0493 - val_acc: 0.9909\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0094 - acc: 0.9972 - val_loss: 0.0493 - val_acc: 0.9909\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 286s 5ms/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0489 - val_acc: 0.9909\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 289s 5ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9908\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 287s 5ms/step - loss: 0.0088 - acc: 0.9972 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 292s 5ms/step - loss: 0.0086 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9909\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 333s 6ms/step - loss: 0.0101 - acc: 0.9968 - val_loss: 0.0491 - val_acc: 0.9909\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 342s 6ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0491 - val_acc: 0.9909\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 321s 5ms/step - loss: 0.0089 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9909\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 315s 5ms/step - loss: 0.0091 - acc: 0.9973 - val_loss: 0.0491 - val_acc: 0.9909\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 408s 7ms/step - loss: 0.0091 - acc: 0.9970 - val_loss: 0.0491 - val_acc: 0.9909\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 386s 6ms/step - loss: 0.0099 - acc: 0.9968 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 414s 7ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 466s 8ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 431s 7ms/step - loss: 0.0093 - acc: 0.9970 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 437s 7ms/step - loss: 0.0090 - acc: 0.9974 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 456s 8ms/step - loss: 0.0088 - acc: 0.9974 - val_loss: 0.0490 - val_acc: 0.9909\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 379s 6ms/step - loss: 0.0081 - acc: 0.9974 - val_loss: 0.0489 - val_acc: 0.9909\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 391s 7ms/step - loss: 0.0092 - acc: 0.9973 - val_loss: 0.0489 - val_acc: 0.9909\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 371s 6ms/step - loss: 0.0094 - acc: 0.9970 - val_loss: 0.0489 - val_acc: 0.9909\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 389s 6ms/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0489 - val_acc: 0.9909\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 382s 6ms/step - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0489 - val_acc: 0.9909\n",
      "Test loss: 0.0489492559044\n",
      "Test accuracy: 0.9909\n",
      "Training for activation SeLU with optimizer Adadelta\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 427s 7ms/step - loss: 0.2473 - acc: 0.9235 - val_loss: 0.0861 - val_acc: 0.9777\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 411s 7ms/step - loss: 0.0829 - acc: 0.9751 - val_loss: 0.0637 - val_acc: 0.9844\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 474s 8ms/step - loss: 0.0578 - acc: 0.9822 - val_loss: 0.0556 - val_acc: 0.9872\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 439s 7ms/step - loss: 0.0437 - acc: 0.9861 - val_loss: 0.0536 - val_acc: 0.9874\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 416s 7ms/step - loss: 0.0389 - acc: 0.9877 - val_loss: 0.0538 - val_acc: 0.9892\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 448s 7ms/step - loss: 0.0326 - acc: 0.9898 - val_loss: 0.0587 - val_acc: 0.9885\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 440s 7ms/step - loss: 0.0274 - acc: 0.9912 - val_loss: 0.0601 - val_acc: 0.9888\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 483s 8ms/step - loss: 0.0242 - acc: 0.9924 - val_loss: 0.0542 - val_acc: 0.9902\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 434s 7ms/step - loss: 0.0226 - acc: 0.9925 - val_loss: 0.0586 - val_acc: 0.9900\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 449s 7ms/step - loss: 0.0200 - acc: 0.9934 - val_loss: 0.0717 - val_acc: 0.9876\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 424s 7ms/step - loss: 0.0184 - acc: 0.9942 - val_loss: 0.0622 - val_acc: 0.9900\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 399s 7ms/step - loss: 0.0164 - acc: 0.9944 - val_loss: 0.0554 - val_acc: 0.9902\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 416s 7ms/step - loss: 0.0160 - acc: 0.9945 - val_loss: 0.0609 - val_acc: 0.9889\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 432s 7ms/step - loss: 0.0147 - acc: 0.9952 - val_loss: 0.0633 - val_acc: 0.9899\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 403s 7ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.0586 - val_acc: 0.9913\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 402s 7ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0581 - val_acc: 0.9911\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 396s 7ms/step - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0583 - val_acc: 0.9912\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 403s 7ms/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0571 - val_acc: 0.9916\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 478s 8ms/step - loss: 0.0087 - acc: 0.9971 - val_loss: 0.0563 - val_acc: 0.9909\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 465s 8ms/step - loss: 0.0079 - acc: 0.9975 - val_loss: 0.0586 - val_acc: 0.9913\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 463s 8ms/step - loss: 0.0082 - acc: 0.9975 - val_loss: 0.0576 - val_acc: 0.9914\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 462s 8ms/step - loss: 0.0073 - acc: 0.9977 - val_loss: 0.0597 - val_acc: 0.9909\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 466s 8ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0589 - val_acc: 0.9910\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 454s 8ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0589 - val_acc: 0.9911\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 447s 7ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0593 - val_acc: 0.9913\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 470s 8ms/step - loss: 0.0070 - acc: 0.9977 - val_loss: 0.0591 - val_acc: 0.9911\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 396s 7ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0604 - val_acc: 0.9911\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 358s 6ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0595 - val_acc: 0.9913\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 320s 5ms/step - loss: 0.0070 - acc: 0.9978 - val_loss: 0.0602 - val_acc: 0.9912\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 311s 5ms/step - loss: 0.0069 - acc: 0.9980 - val_loss: 0.0606 - val_acc: 0.9912\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 305s 5ms/step - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0609 - val_acc: 0.9912\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0061 - acc: 0.9980 - val_loss: 0.0609 - val_acc: 0.9913\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0060 - acc: 0.9979 - val_loss: 0.0608 - val_acc: 0.9911\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0606 - val_acc: 0.9911\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0065 - acc: 0.9979 - val_loss: 0.0607 - val_acc: 0.9913\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0607 - val_acc: 0.9913\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.0605 - val_acc: 0.9913\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 317s 5ms/step - loss: 0.0060 - acc: 0.9981 - val_loss: 0.0604 - val_acc: 0.9911\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0605 - val_acc: 0.9911\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0605 - val_acc: 0.9911\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0064 - acc: 0.9981 - val_loss: 0.0604 - val_acc: 0.9911\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0066 - acc: 0.9979 - val_loss: 0.0604 - val_acc: 0.9912\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0059 - acc: 0.9982 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 305s 5ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0065 - acc: 0.9981 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0066 - acc: 0.9978 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 305s 5ms/step - loss: 0.0057 - acc: 0.9982 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0068 - acc: 0.9979 - val_loss: 0.0605 - val_acc: 0.9912\n",
      "Test loss: 0.060523664322\n",
      "Test accuracy: 0.9912\n",
      "Training for activation SeLU with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.2135 - acc: 0.9354 - val_loss: 0.0762 - val_acc: 0.9786\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0759 - acc: 0.9775 - val_loss: 0.0620 - val_acc: 0.9860\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0529 - acc: 0.9841 - val_loss: 0.0545 - val_acc: 0.9873\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0408 - acc: 0.9868 - val_loss: 0.0596 - val_acc: 0.9890\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0308 - acc: 0.9897 - val_loss: 0.0458 - val_acc: 0.9903\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0252 - acc: 0.9919 - val_loss: 0.0531 - val_acc: 0.9892\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.0208 - acc: 0.9931 - val_loss: 0.0529 - val_acc: 0.9896\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0194 - acc: 0.9941 - val_loss: 0.0663 - val_acc: 0.9893\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0162 - acc: 0.9946 - val_loss: 0.0635 - val_acc: 0.9899\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0140 - acc: 0.9955 - val_loss: 0.0623 - val_acc: 0.9905\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0124 - acc: 0.9956 - val_loss: 0.0589 - val_acc: 0.9904\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0121 - acc: 0.9961 - val_loss: 0.0589 - val_acc: 0.9906\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 299s 5ms/step - loss: 0.0104 - acc: 0.9967 - val_loss: 0.0663 - val_acc: 0.9904\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0101 - acc: 0.9965 - val_loss: 0.0694 - val_acc: 0.9904\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0094 - acc: 0.9969 - val_loss: 0.0752 - val_acc: 0.9900\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0769 - val_acc: 0.9897\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0647 - val_acc: 0.9905\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0044 - acc: 0.9985 - val_loss: 0.0699 - val_acc: 0.9905\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0687 - val_acc: 0.9906\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0688 - val_acc: 0.9903\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0650 - val_acc: 0.9907\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0036 - acc: 0.9988 - val_loss: 0.0661 - val_acc: 0.9904\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0666 - val_acc: 0.9906\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0679 - val_acc: 0.9908\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0650 - val_acc: 0.9909\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0028 - acc: 0.9991 - val_loss: 0.0645 - val_acc: 0.9911\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0029 - acc: 0.9991 - val_loss: 0.0623 - val_acc: 0.9914\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0646 - val_acc: 0.9914\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0681 - val_acc: 0.9909\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 0.0672 - val_acc: 0.9910\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0023 - acc: 0.9992 - val_loss: 0.0681 - val_acc: 0.9916\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0667 - val_acc: 0.9913\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0665 - val_acc: 0.9915\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0639 - val_acc: 0.9914\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0643 - val_acc: 0.9919\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0706 - val_acc: 0.9917\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 310s 5ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0676 - val_acc: 0.9910\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0667 - val_acc: 0.9914\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0680 - val_acc: 0.9912\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 300s 5ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0705 - val_acc: 0.9919\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 301s 5ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0694 - val_acc: 0.9912\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0676 - val_acc: 0.9917\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0668 - val_acc: 0.9915\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0018 - acc: 0.9994 - val_loss: 0.0673 - val_acc: 0.9915\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0676 - val_acc: 0.9914\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0671 - val_acc: 0.9914\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0664 - val_acc: 0.9917\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0672 - val_acc: 0.9919\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 293s 5ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0671 - val_acc: 0.9918\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 294s 5ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0671 - val_acc: 0.9918\n",
      "Test loss: 0.0671472115266\n",
      "Test accuracy: 0.9918\n",
      "Training for activation SeLU with optimizer Nadam\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.2007 - acc: 0.9422 - val_loss: 0.0980 - val_acc: 0.9785\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.1038 - acc: 0.9721 - val_loss: 0.1098 - val_acc: 0.9797\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0931 - acc: 0.9755 - val_loss: 0.0732 - val_acc: 0.9880\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0845 - acc: 0.9789 - val_loss: 0.0961 - val_acc: 0.9839\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0832 - acc: 0.9795 - val_loss: 0.0932 - val_acc: 0.9857\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0782 - acc: 0.9805 - val_loss: 0.1034 - val_acc: 0.9832\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0799 - acc: 0.9817 - val_loss: 0.0967 - val_acc: 0.9868\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0780 - acc: 0.9830 - val_loss: 0.1282 - val_acc: 0.9827\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0793 - acc: 0.9825 - val_loss: 0.1227 - val_acc: 0.9840\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0371 - acc: 0.9904 - val_loss: 0.0819 - val_acc: 0.9897\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0256 - acc: 0.9930 - val_loss: 0.0704 - val_acc: 0.9900\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0206 - acc: 0.9940 - val_loss: 0.0778 - val_acc: 0.9900\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 305s 5ms/step - loss: 0.0195 - acc: 0.9944 - val_loss: 0.0754 - val_acc: 0.9900\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0160 - acc: 0.9954 - val_loss: 0.0814 - val_acc: 0.9893\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0137 - acc: 0.9962 - val_loss: 0.0838 - val_acc: 0.9895\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.0754 - val_acc: 0.9903\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0120 - acc: 0.9964 - val_loss: 0.0755 - val_acc: 0.9901\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0141 - acc: 0.9960 - val_loss: 0.0714 - val_acc: 0.9905\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0116 - acc: 0.9968 - val_loss: 0.0721 - val_acc: 0.9909\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0122 - acc: 0.9964 - val_loss: 0.0671 - val_acc: 0.9908\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0099 - acc: 0.9972 - val_loss: 0.0811 - val_acc: 0.9911\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0115 - acc: 0.9964 - val_loss: 0.0864 - val_acc: 0.9898\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 302s 5ms/step - loss: 0.0097 - acc: 0.9972 - val_loss: 0.0847 - val_acc: 0.9902\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0807 - val_acc: 0.9903\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 0.0851 - val_acc: 0.9912\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0083 - acc: 0.9976 - val_loss: 0.0954 - val_acc: 0.9895\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0946 - val_acc: 0.9906\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0066 - acc: 0.9980 - val_loss: 0.0885 - val_acc: 0.9909\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0901 - val_acc: 0.9909\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0819 - val_acc: 0.9914\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0835 - val_acc: 0.9911\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.0837 - val_acc: 0.9910\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 305s 5ms/step - loss: 0.0050 - acc: 0.9983 - val_loss: 0.0835 - val_acc: 0.9912\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 304s 5ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0864 - val_acc: 0.9912\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 327s 5ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0888 - val_acc: 0.9911\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 313s 5ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0829 - val_acc: 0.9913\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 316s 5ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0820 - val_acc: 0.9914\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 358s 6ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0835 - val_acc: 0.9910\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 353s 6ms/step - loss: 0.0039 - acc: 0.9989 - val_loss: 0.0838 - val_acc: 0.9910\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 345s 6ms/step - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0829 - val_acc: 0.9909\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 383s 6ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0826 - val_acc: 0.9910\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 359s 6ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0806 - val_acc: 0.9912\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 301s 5ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0819 - val_acc: 0.9912\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 309s 5ms/step - loss: 0.0035 - acc: 0.9989 - val_loss: 0.0820 - val_acc: 0.9912\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.0037 - acc: 0.9989 - val_loss: 0.0821 - val_acc: 0.9912\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0820 - val_acc: 0.9912\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0819 - val_acc: 0.9911\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 296s 5ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0822 - val_acc: 0.9912\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 295s 5ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 0.0819 - val_acc: 0.9911\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 297s 5ms/step - loss: 0.0038 - acc: 0.9989 - val_loss: 0.0817 - val_acc: 0.9912\n",
      "Test loss: 0.0816728962701\n",
      "Test accuracy: 0.9912\n"
     ]
    }
   ],
   "source": [
    "for opt in optimizers:\n",
    "    print(\"Training for activation SeLU with optimizer \" + opt)\n",
    "    for i in range(experiments):\n",
    "        model_name = 'mnist_cnn_selu_' + opt + '_' + str(i + start) \n",
    "        \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                         activation='selu', kernel_initializer='lecun_normal',\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='selu', kernel_initializer='lecun_normal'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(AlphaDropout(0.2))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128, activation='selu', kernel_initializer='lecun_normal'))\n",
    "        model.add(AlphaDropout(0.2))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        if opt == 'rmsp':\n",
    "            optimizer = keras.optimizers.rmsprop()                \n",
    "        elif opt == 'adam':\n",
    "            optimizer = keras.optimizers.Adam()\n",
    "        elif opt == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD()\n",
    "        elif opt == 'Adagrad':\n",
    "            optimizer = keras.optimizers.Adagrad()\n",
    "        elif opt == 'Adadelta':\n",
    "            optimizer = keras.optimizers.Adadelta()\n",
    "        elif opt == 'Adamax':\n",
    "            optimizer = keras.optimizers.Adamax()\n",
    "        elif opt == 'Nadam':\n",
    "            optimizer = keras.optimizers.Nadam()\n",
    "\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "        print('-'*30)\n",
    "        print('Experiment', i+1)\n",
    "\n",
    "        csv_logger = CSVLogger('./logs/%s_%d.csv' % (model_name, units), append=False, separator=';')\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, verbose=0, mode='auto', epsilon=0.0001, cooldown=2, min_lr=0)\n",
    "#         tb = TensorBoard(log_dir='./tb_logs/' + model_name + '_' + str(units), histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        model_path = os.path.join(save_dir, model_name + \".h5\")\n",
    "#         model.save(model_path)\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
