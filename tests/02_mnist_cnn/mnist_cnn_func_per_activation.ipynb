{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rmks/anaconda/envs/tf/lib/python3.5/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/Users/rmks/anaconda/envs/tf/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import CSVLogger, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
    "import os\n",
    "from keras.layers.noise import AlphaDropout\n",
    "import keras.activations\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "units = 64\n",
    "experiments = 1\n",
    "start = 2\n",
    "add_final_dense = False\n",
    "activations = ['sigmoid', 'tanh', 'relu', 'linear', 'elu', 'softplus', 'softsign', 'hard_sigmoid', 'LeakyReLU', 'ThresholdedReLU']\n",
    "# activations = ['ThresholdedReLU']\n",
    "# PReLU is not used, since it does not currently support variable inputs\n",
    "optimizers = ['rmsp', 'adam', 'sgd', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']\n",
    "# optimizers = ['Nadam']\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "start_time = time.time()\n",
    "counter = 0\n",
    "total_items = (len(activations) + 1 )* len(optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train per each activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training for activation sigmoid with optimizer rmsp\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.8707 - acc: 0.7268 - val_loss: 0.3968 - val_acc: 0.8777\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 204s 3ms/step - loss: 0.3204 - acc: 0.9035 - val_loss: 0.2339 - val_acc: 0.9318\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.1777 - acc: 0.9471 - val_loss: 0.1281 - val_acc: 0.9623\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.1190 - acc: 0.9645 - val_loss: 0.0902 - val_acc: 0.9713\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0953 - acc: 0.9710 - val_loss: 0.0781 - val_acc: 0.9761\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0841 - acc: 0.9746 - val_loss: 0.0700 - val_acc: 0.9791\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0765 - acc: 0.9772 - val_loss: 0.0649 - val_acc: 0.9806\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0705 - acc: 0.9789 - val_loss: 0.0590 - val_acc: 0.9812\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0682 - acc: 0.9796 - val_loss: 0.0609 - val_acc: 0.9815\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0639 - acc: 0.9809 - val_loss: 0.0609 - val_acc: 0.9800\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0616 - acc: 0.9820 - val_loss: 0.0548 - val_acc: 0.9828\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0592 - acc: 0.9823 - val_loss: 0.0562 - val_acc: 0.9823\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0573 - acc: 0.9828 - val_loss: 0.0531 - val_acc: 0.9841\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0553 - acc: 0.9832 - val_loss: 0.0514 - val_acc: 0.9842\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0526 - acc: 0.9840 - val_loss: 0.0513 - val_acc: 0.9848\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0523 - acc: 0.9847 - val_loss: 0.0550 - val_acc: 0.9841\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0524 - acc: 0.9846 - val_loss: 0.0479 - val_acc: 0.9855\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0485 - acc: 0.9861 - val_loss: 0.0531 - val_acc: 0.9845\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0498 - acc: 0.9856 - val_loss: 0.0480 - val_acc: 0.9856\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0472 - acc: 0.9863 - val_loss: 0.0504 - val_acc: 0.9845\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0459 - acc: 0.9867 - val_loss: 0.0589 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0406 - acc: 0.9880 - val_loss: 0.0456 - val_acc: 0.9861\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0394 - acc: 0.9884 - val_loss: 0.0456 - val_acc: 0.9862\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0392 - acc: 0.9887 - val_loss: 0.0458 - val_acc: 0.9853\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0385 - acc: 0.9889 - val_loss: 0.0444 - val_acc: 0.9862\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0387 - acc: 0.9885 - val_loss: 0.0441 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0366 - acc: 0.9895 - val_loss: 0.0442 - val_acc: 0.9866\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0366 - acc: 0.9893 - val_loss: 0.0446 - val_acc: 0.9863\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0385 - acc: 0.9886 - val_loss: 0.0440 - val_acc: 0.9859\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0382 - acc: 0.9891 - val_loss: 0.0442 - val_acc: 0.9858\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0376 - acc: 0.9891 - val_loss: 0.0436 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0368 - acc: 0.9894 - val_loss: 0.0438 - val_acc: 0.9859\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0376 - acc: 0.9893 - val_loss: 0.0439 - val_acc: 0.9858\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0370 - acc: 0.9891 - val_loss: 0.0440 - val_acc: 0.9859\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0370 - acc: 0.9893 - val_loss: 0.0441 - val_acc: 0.9859\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0369 - acc: 0.9894 - val_loss: 0.0441 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0379 - acc: 0.9892 - val_loss: 0.0441 - val_acc: 0.9858\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0369 - acc: 0.9896 - val_loss: 0.0441 - val_acc: 0.9858\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0379 - acc: 0.9891 - val_loss: 0.0441 - val_acc: 0.9858\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0363 - acc: 0.9893 - val_loss: 0.0441 - val_acc: 0.9858\n",
      "Test loss: 0.04410293909445754\n",
      "Test accuracy: 0.9858\n",
      "Remaining time: 6 days 23 hours 07 minutes 41 seconds\n",
      "\n",
      "Training for activation sigmoid with optimizer adam\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.9924 - acc: 0.6731 - val_loss: 0.3145 - val_acc: 0.9058\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.2655 - acc: 0.9213 - val_loss: 0.1760 - val_acc: 0.9536\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.1496 - acc: 0.9561 - val_loss: 0.1050 - val_acc: 0.9696\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.1055 - acc: 0.9689 - val_loss: 0.0819 - val_acc: 0.9763\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0868 - acc: 0.9738 - val_loss: 0.0644 - val_acc: 0.9810\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0738 - acc: 0.9776 - val_loss: 0.0595 - val_acc: 0.9822\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0656 - acc: 0.9797 - val_loss: 0.0565 - val_acc: 0.9815\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0593 - acc: 0.9820 - val_loss: 0.0545 - val_acc: 0.9824\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0553 - acc: 0.9829 - val_loss: 0.0556 - val_acc: 0.9822\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0497 - acc: 0.9844 - val_loss: 0.0501 - val_acc: 0.9839\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0462 - acc: 0.9858 - val_loss: 0.0550 - val_acc: 0.9824\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0433 - acc: 0.9865 - val_loss: 0.0526 - val_acc: 0.9843\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0408 - acc: 0.9870 - val_loss: 0.0488 - val_acc: 0.9853\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0374 - acc: 0.9878 - val_loss: 0.0501 - val_acc: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0350 - acc: 0.9889 - val_loss: 0.0564 - val_acc: 0.9822\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0337 - acc: 0.9891 - val_loss: 0.0457 - val_acc: 0.9853\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0310 - acc: 0.9898 - val_loss: 0.0488 - val_acc: 0.9842\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0247 - acc: 0.9926 - val_loss: 0.0457 - val_acc: 0.9859\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0452 - val_acc: 0.9857\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0220 - acc: 0.9932 - val_loss: 0.0461 - val_acc: 0.9856\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0220 - acc: 0.9931 - val_loss: 0.0467 - val_acc: 0.9858\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0209 - acc: 0.9937 - val_loss: 0.0459 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0196 - acc: 0.9941 - val_loss: 0.0453 - val_acc: 0.9855\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0193 - acc: 0.9941 - val_loss: 0.0448 - val_acc: 0.9852\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0192 - acc: 0.9939 - val_loss: 0.0448 - val_acc: 0.9858\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0189 - acc: 0.9942 - val_loss: 0.0452 - val_acc: 0.9859\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0460 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0189 - acc: 0.9941 - val_loss: 0.0451 - val_acc: 0.9854\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0450 - val_acc: 0.9860\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0185 - acc: 0.9947 - val_loss: 0.0448 - val_acc: 0.9859\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0448 - val_acc: 0.9861\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0184 - acc: 0.9944 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0190 - acc: 0.9940 - val_loss: 0.0449 - val_acc: 0.9858\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0183 - acc: 0.9941 - val_loss: 0.0449 - val_acc: 0.9857\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0186 - acc: 0.9941 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0184 - acc: 0.9943 - val_loss: 0.0448 - val_acc: 0.9859\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0187 - acc: 0.9945 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0185 - acc: 0.9946 - val_loss: 0.0449 - val_acc: 0.9860\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0187 - acc: 0.9945 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0183 - acc: 0.9946 - val_loss: 0.0448 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Test loss: 0.04483505396270193\n",
      "Test accuracy: 0.986\n",
      "Remaining time: 6 days 16 hours 26 minutes 49 seconds\n",
      "\n",
      "Training for activation sigmoid with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 2.3930 - acc: 0.1118 - val_loss: 2.3129 - val_acc: 0.0982\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 1.9183 - acc: 0.3945 - val_loss: 0.9223 - val_acc: 0.7916\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.5938 - acc: 0.8379 - val_loss: 0.4246 - val_acc: 0.8806\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.4186 - acc: 0.8753 - val_loss: 0.3552 - val_acc: 0.8974\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.3776 - acc: 0.8871 - val_loss: 0.3365 - val_acc: 0.9025\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.3581 - acc: 0.8919 - val_loss: 0.3207 - val_acc: 0.9050\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.3446 - acc: 0.8973 - val_loss: 0.3091 - val_acc: 0.9112\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.3351 - acc: 0.9002 - val_loss: 0.2978 - val_acc: 0.9132\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.3275 - acc: 0.9028 - val_loss: 0.2969 - val_acc: 0.9127\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.3216 - acc: 0.9063 - val_loss: 0.2863 - val_acc: 0.9168\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.3150 - acc: 0.9065 - val_loss: 0.2850 - val_acc: 0.9189\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.3088 - acc: 0.9082 - val_loss: 0.2766 - val_acc: 0.9205\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.3021 - acc: 0.9111 - val_loss: 0.2738 - val_acc: 0.9207\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2975 - acc: 0.9132 - val_loss: 0.2708 - val_acc: 0.9235\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2934 - acc: 0.9129 - val_loss: 0.2636 - val_acc: 0.9250\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2888 - acc: 0.9149 - val_loss: 0.2603 - val_acc: 0.9263\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2842 - acc: 0.9178 - val_loss: 0.2583 - val_acc: 0.9262\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2796 - acc: 0.9183 - val_loss: 0.2602 - val_acc: 0.9260\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2766 - acc: 0.9192 - val_loss: 0.2508 - val_acc: 0.9306\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2726 - acc: 0.9200 - val_loss: 0.2507 - val_acc: 0.9273\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2679 - acc: 0.9220 - val_loss: 0.2517 - val_acc: 0.9281\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2658 - acc: 0.9222 - val_loss: 0.2469 - val_acc: 0.9304\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2626 - acc: 0.9232 - val_loss: 0.2366 - val_acc: 0.9344\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2596 - acc: 0.9242 - val_loss: 0.2362 - val_acc: 0.9342\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2562 - acc: 0.9251 - val_loss: 0.2308 - val_acc: 0.9357\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2544 - acc: 0.9248 - val_loss: 0.2298 - val_acc: 0.9366\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2511 - acc: 0.9268 - val_loss: 0.2297 - val_acc: 0.9357\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2482 - acc: 0.9276 - val_loss: 0.2248 - val_acc: 0.9375\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2451 - acc: 0.9290 - val_loss: 0.2234 - val_acc: 0.9376\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2423 - acc: 0.9288 - val_loss: 0.2292 - val_acc: 0.9352\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2418 - acc: 0.9295 - val_loss: 0.2184 - val_acc: 0.9390\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2401 - acc: 0.9300 - val_loss: 0.2189 - val_acc: 0.9402\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2364 - acc: 0.9297 - val_loss: 0.2164 - val_acc: 0.9383\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2340 - acc: 0.9316 - val_loss: 0.2130 - val_acc: 0.9406\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2323 - acc: 0.9326 - val_loss: 0.2133 - val_acc: 0.9406\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.2297 - acc: 0.9335 - val_loss: 0.2100 - val_acc: 0.9417\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.2287 - acc: 0.9338 - val_loss: 0.2090 - val_acc: 0.9411\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2255 - acc: 0.9348 - val_loss: 0.2057 - val_acc: 0.9436\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2249 - acc: 0.9344 - val_loss: 0.2040 - val_acc: 0.9430\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.2238 - acc: 0.9351 - val_loss: 0.2020 - val_acc: 0.9434\n",
      "Test loss: 0.20203989427685737\n",
      "Test accuracy: 0.9434\n",
      "Remaining time: 6 days 11 hours 20 minutes 09 seconds\n",
      "\n",
      "Training for activation sigmoid with optimizer Adagrad\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.2914 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 14.3070 - acc: 0.1124 - val_loss: 14.2887 - val_acc: 0.1135\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 2.5599996433811613e-08.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 14.28869146270752\n",
      "Test accuracy: 0.1135\n",
      "Remaining time: 6 days 7 hours 55 minutes 09 seconds\n",
      "\n",
      "Training for activation sigmoid with optimizer Adadelta\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.9850 - acc: 0.6684 - val_loss: 0.3588 - val_acc: 0.8908\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.3193 - acc: 0.9031 - val_loss: 0.2420 - val_acc: 0.9284\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.1708 - acc: 0.9498 - val_loss: 0.1231 - val_acc: 0.9640\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.1167 - acc: 0.9651 - val_loss: 0.0943 - val_acc: 0.9701\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0941 - acc: 0.9719 - val_loss: 0.0865 - val_acc: 0.9746\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0820 - acc: 0.9753 - val_loss: 0.0717 - val_acc: 0.9780\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0752 - acc: 0.9773 - val_loss: 0.0639 - val_acc: 0.9806\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0692 - acc: 0.9794 - val_loss: 0.0632 - val_acc: 0.9803\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0648 - acc: 0.9808 - val_loss: 0.0659 - val_acc: 0.9805\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0614 - acc: 0.9812 - val_loss: 0.0596 - val_acc: 0.9810\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0598 - acc: 0.9817 - val_loss: 0.0565 - val_acc: 0.9827\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0563 - acc: 0.9826 - val_loss: 0.0534 - val_acc: 0.9827\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0547 - acc: 0.9830 - val_loss: 0.0507 - val_acc: 0.9843\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0530 - acc: 0.9840 - val_loss: 0.0516 - val_acc: 0.9826\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0516 - acc: 0.9846 - val_loss: 0.0501 - val_acc: 0.9838\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0499 - acc: 0.9847 - val_loss: 0.0464 - val_acc: 0.9858\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0486 - acc: 0.9855 - val_loss: 0.0469 - val_acc: 0.9848\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0468 - acc: 0.9856 - val_loss: 0.0499 - val_acc: 0.9849\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0452 - acc: 0.9863 - val_loss: 0.0473 - val_acc: 0.9848\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0456 - acc: 0.9860 - val_loss: 0.0481 - val_acc: 0.9835\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.2.\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 202s 3ms/step - loss: 0.0403 - acc: 0.9874 - val_loss: 0.0455 - val_acc: 0.9859\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0391 - acc: 0.9879 - val_loss: 0.0448 - val_acc: 0.9861\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 211s 4ms/step - loss: 0.0392 - acc: 0.9886 - val_loss: 0.0443 - val_acc: 0.9857\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0392 - acc: 0.9880 - val_loss: 0.0457 - val_acc: 0.9851\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0387 - acc: 0.9887 - val_loss: 0.0450 - val_acc: 0.9855\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0386 - acc: 0.9886 - val_loss: 0.0450 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0375 - acc: 0.9888 - val_loss: 0.0446 - val_acc: 0.9859\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0386 - acc: 0.9885 - val_loss: 0.0449 - val_acc: 0.9852\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0373 - acc: 0.9889 - val_loss: 0.0447 - val_acc: 0.9851\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0379 - acc: 0.9884 - val_loss: 0.0448 - val_acc: 0.9854\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0381 - acc: 0.9884 - val_loss: 0.0447 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0386 - acc: 0.9881 - val_loss: 0.0447 - val_acc: 0.9854\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0380 - acc: 0.9884 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0376 - acc: 0.9887 - val_loss: 0.0446 - val_acc: 0.9855\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0381 - acc: 0.9890 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0366 - acc: 0.9892 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0377 - acc: 0.9887 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0375 - acc: 0.9886 - val_loss: 0.0446 - val_acc: 0.9855\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0375 - acc: 0.9889 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0372 - acc: 0.9885 - val_loss: 0.0446 - val_acc: 0.9854\n",
      "Test loss: 0.0445948454036843\n",
      "Test accuracy: 0.9854\n",
      "Remaining time: 6 days 6 hours 21 minutes 57 seconds\n",
      "\n",
      "Training for activation sigmoid with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 2.1016 - acc: 0.2983 - val_loss: 0.4933 - val_acc: 0.8430\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.4108 - acc: 0.8747 - val_loss: 0.3441 - val_acc: 0.8972\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.3275 - acc: 0.9011 - val_loss: 0.2482 - val_acc: 0.9293\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.2403 - acc: 0.9296 - val_loss: 0.1730 - val_acc: 0.9494\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.1623 - acc: 0.9526 - val_loss: 0.1147 - val_acc: 0.9661\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.1197 - acc: 0.9648 - val_loss: 0.0951 - val_acc: 0.9707\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0989 - acc: 0.9707 - val_loss: 0.0771 - val_acc: 0.9771\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0852 - acc: 0.9745 - val_loss: 0.0724 - val_acc: 0.9784\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0765 - acc: 0.9767 - val_loss: 0.0718 - val_acc: 0.9790\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0700 - acc: 0.9789 - val_loss: 0.0627 - val_acc: 0.9802\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0638 - acc: 0.9806 - val_loss: 0.0606 - val_acc: 0.9804\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0603 - acc: 0.9817 - val_loss: 0.0557 - val_acc: 0.9817\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0555 - acc: 0.9830 - val_loss: 0.0545 - val_acc: 0.9825\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0529 - acc: 0.9842 - val_loss: 0.0554 - val_acc: 0.9821\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0503 - acc: 0.9848 - val_loss: 0.0555 - val_acc: 0.9830\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0473 - acc: 0.9852 - val_loss: 0.0497 - val_acc: 0.9840\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0453 - acc: 0.9863 - val_loss: 0.0482 - val_acc: 0.9842\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0432 - acc: 0.9863 - val_loss: 0.0482 - val_acc: 0.9841\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0415 - acc: 0.9871 - val_loss: 0.0478 - val_acc: 0.9848\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0397 - acc: 0.9875 - val_loss: 0.0468 - val_acc: 0.9850\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0375 - acc: 0.9887 - val_loss: 0.0476 - val_acc: 0.9848\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0372 - acc: 0.9887 - val_loss: 0.0482 - val_acc: 0.9846\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0345 - acc: 0.9893 - val_loss: 0.0455 - val_acc: 0.9862\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0343 - acc: 0.9894 - val_loss: 0.0497 - val_acc: 0.9855\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0331 - acc: 0.9899 - val_loss: 0.0462 - val_acc: 0.9851\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0315 - acc: 0.9901 - val_loss: 0.0438 - val_acc: 0.9851\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0302 - acc: 0.9907 - val_loss: 0.0460 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0265 - acc: 0.9920 - val_loss: 0.0440 - val_acc: 0.9863\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0265 - acc: 0.9916 - val_loss: 0.0437 - val_acc: 0.9872\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0260 - acc: 0.9921 - val_loss: 0.0441 - val_acc: 0.9862\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0259 - acc: 0.9924 - val_loss: 0.0437 - val_acc: 0.9872\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0261 - acc: 0.9920 - val_loss: 0.0426 - val_acc: 0.9864\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0248 - acc: 0.9929 - val_loss: 0.0428 - val_acc: 0.9867\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0242 - acc: 0.9929 - val_loss: 0.0426 - val_acc: 0.9873\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0237 - acc: 0.9931 - val_loss: 0.0424 - val_acc: 0.9876\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0235 - acc: 0.9932 - val_loss: 0.0425 - val_acc: 0.9871\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0238 - acc: 0.9930 - val_loss: 0.0425 - val_acc: 0.9870\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0246 - acc: 0.9929 - val_loss: 0.0426 - val_acc: 0.9873\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0240 - acc: 0.9931 - val_loss: 0.0425 - val_acc: 0.9872\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0239 - acc: 0.9927 - val_loss: 0.0424 - val_acc: 0.9874\n",
      "Test loss: 0.042371149355568925\n",
      "Test accuracy: 0.9874\n",
      "Remaining time: 6 days 4 hours 21 minutes 30 seconds\n",
      "\n",
      "Training for activation sigmoid with optimizer Nadam\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.8133 - acc: 0.7439 - val_loss: 0.2314 - val_acc: 0.9341\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.1723 - acc: 0.9487 - val_loss: 0.1051 - val_acc: 0.9687\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.1033 - acc: 0.9693 - val_loss: 0.0811 - val_acc: 0.9750\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0825 - acc: 0.9747 - val_loss: 0.0669 - val_acc: 0.9795\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0698 - acc: 0.9783 - val_loss: 0.0583 - val_acc: 0.9807\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0630 - acc: 0.9804 - val_loss: 0.0616 - val_acc: 0.9803\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0567 - acc: 0.9822 - val_loss: 0.0506 - val_acc: 0.9836\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0507 - acc: 0.9842 - val_loss: 0.0541 - val_acc: 0.9833\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0476 - acc: 0.9851 - val_loss: 0.0562 - val_acc: 0.9830\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0437 - acc: 0.9860 - val_loss: 0.0545 - val_acc: 0.9831\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0400 - acc: 0.9873 - val_loss: 0.0510 - val_acc: 0.9843\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0385 - acc: 0.9876 - val_loss: 0.0547 - val_acc: 0.9834\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0359 - acc: 0.9882 - val_loss: 0.0540 - val_acc: 0.9835\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0326 - acc: 0.9891 - val_loss: 0.0512 - val_acc: 0.9848\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0309 - acc: 0.9898 - val_loss: 0.0529 - val_acc: 0.9831\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0312 - acc: 0.9897 - val_loss: 0.0579 - val_acc: 0.9835\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0262 - acc: 0.9910 - val_loss: 0.0595 - val_acc: 0.9830\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0279 - acc: 0.9903 - val_loss: 0.0549 - val_acc: 0.9845\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0180 - acc: 0.9941 - val_loss: 0.0510 - val_acc: 0.9857\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0501 - val_acc: 0.9860\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0502 - val_acc: 0.9857\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0150 - acc: 0.9952 - val_loss: 0.0518 - val_acc: 0.9859\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0153 - acc: 0.9949 - val_loss: 0.0509 - val_acc: 0.9861\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0508 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0132 - acc: 0.9961 - val_loss: 0.0508 - val_acc: 0.9859\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0132 - acc: 0.9959 - val_loss: 0.0507 - val_acc: 0.9861\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0515 - val_acc: 0.9862\n",
      "Epoch 28/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0123 - acc: 0.9965 - val_loss: 0.0509 - val_acc: 0.9860\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0133 - acc: 0.9957 - val_loss: 0.0504 - val_acc: 0.9861\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0130 - acc: 0.9956 - val_loss: 0.0507 - val_acc: 0.9861\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0506 - val_acc: 0.9863\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0122 - acc: 0.9960 - val_loss: 0.0505 - val_acc: 0.9863\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0506 - val_acc: 0.9864\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0506 - val_acc: 0.9863\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0118 - acc: 0.9963 - val_loss: 0.0506 - val_acc: 0.9864\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0114 - acc: 0.9964 - val_loss: 0.0506 - val_acc: 0.9865\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0506 - val_acc: 0.9866\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 0.0507 - val_acc: 0.9865\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0119 - acc: 0.9960 - val_loss: 0.0508 - val_acc: 0.9865\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0119 - acc: 0.9963 - val_loss: 0.0506 - val_acc: 0.9864\n",
      "Test loss: 0.05057651520556683\n",
      "Test accuracy: 0.9864\n",
      "Remaining time: 6 days 2 hours 39 minutes 48 seconds\n",
      "\n",
      "Training for activation tanh with optimizer rmsp\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.1837 - acc: 0.9456 - val_loss: 0.0809 - val_acc: 0.9749\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0802 - acc: 0.9758 - val_loss: 0.0642 - val_acc: 0.9806\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0652 - acc: 0.9807 - val_loss: 0.0614 - val_acc: 0.9815\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0566 - acc: 0.9835 - val_loss: 0.0724 - val_acc: 0.9790\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0514 - acc: 0.9845 - val_loss: 0.0635 - val_acc: 0.9809\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0456 - acc: 0.9871 - val_loss: 0.0670 - val_acc: 0.9810\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0390 - acc: 0.9887 - val_loss: 0.0686 - val_acc: 0.9821\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0368 - acc: 0.9892 - val_loss: 0.0745 - val_acc: 0.9805\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0333 - acc: 0.9904 - val_loss: 0.0735 - val_acc: 0.9842\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0286 - acc: 0.9917 - val_loss: 0.0870 - val_acc: 0.9829\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0279 - acc: 0.9919 - val_loss: 0.0921 - val_acc: 0.9814\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0256 - acc: 0.9924 - val_loss: 0.0900 - val_acc: 0.9820\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0211 - acc: 0.9936 - val_loss: 0.0826 - val_acc: 0.9848\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0215 - acc: 0.9936 - val_loss: 0.0949 - val_acc: 0.9830\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0174 - acc: 0.9949 - val_loss: 0.1067 - val_acc: 0.9814\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0166 - acc: 0.9951 - val_loss: 0.0903 - val_acc: 0.9836\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0162 - acc: 0.9952 - val_loss: 0.0970 - val_acc: 0.9844\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0064 - acc: 0.9980 - val_loss: 0.0868 - val_acc: 0.9856\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0911 - val_acc: 0.9858\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0038 - acc: 0.9988 - val_loss: 0.0857 - val_acc: 0.9859\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0034 - acc: 0.9991 - val_loss: 0.0883 - val_acc: 0.9860\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0033 - acc: 0.9990 - val_loss: 0.0838 - val_acc: 0.9864\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0869 - val_acc: 0.9853\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0861 - val_acc: 0.9858\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0848 - val_acc: 0.9860\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0024 - acc: 0.9993 - val_loss: 0.0842 - val_acc: 0.9862\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 0.0850 - val_acc: 0.9864\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0849 - val_acc: 0.9861\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0851 - val_acc: 0.9861\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0852 - val_acc: 0.9859\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0854 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0856 - val_acc: 0.9861\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0856 - val_acc: 0.9862\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0857 - val_acc: 0.9863\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0856 - val_acc: 0.9863\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0857 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0858 - val_acc: 0.9860\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0858 - val_acc: 0.9861\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0858 - val_acc: 0.9859\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0858 - val_acc: 0.9860\n",
      "Test loss: 0.08580243387180948\n",
      "Test accuracy: 0.986\n",
      "Remaining time: 6 days 0 hours 11 minutes 46 seconds\n",
      "\n",
      "Training for activation tanh with optimizer adam\n",
      "------------------------------\n",
      "Experiment 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.2051 - acc: 0.9384 - val_loss: 0.0880 - val_acc: 0.9721\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0822 - acc: 0.9753 - val_loss: 0.0673 - val_acc: 0.9799\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0633 - acc: 0.9805 - val_loss: 0.0596 - val_acc: 0.9808\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0552 - acc: 0.9825 - val_loss: 0.0797 - val_acc: 0.9759\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0521 - acc: 0.9836 - val_loss: 0.0694 - val_acc: 0.9799\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0463 - acc: 0.9850 - val_loss: 0.0726 - val_acc: 0.9799\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0385 - acc: 0.9877 - val_loss: 0.0715 - val_acc: 0.9800\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0196 - acc: 0.9937 - val_loss: 0.0575 - val_acc: 0.9853\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0137 - acc: 0.9955 - val_loss: 0.0568 - val_acc: 0.9849\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0583 - val_acc: 0.9847\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0641 - val_acc: 0.9843\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0615 - val_acc: 0.9848\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0599 - val_acc: 0.9848\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0589 - val_acc: 0.9846\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0600 - val_acc: 0.9853\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0067 - acc: 0.9981 - val_loss: 0.0598 - val_acc: 0.9847\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0066 - acc: 0.9981 - val_loss: 0.0592 - val_acc: 0.9852\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0060 - acc: 0.9985 - val_loss: 0.0594 - val_acc: 0.9847\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0590 - val_acc: 0.9846\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 12513s 209ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0595 - val_acc: 0.9848\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0598 - val_acc: 0.9848\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0596 - val_acc: 0.9851\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0058 - acc: 0.9986 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0057 - acc: 0.9986 - val_loss: 0.0595 - val_acc: 0.9850\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0596 - val_acc: 0.9851\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0597 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0055 - acc: 0.9988 - val_loss: 0.0597 - val_acc: 0.9850\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0052 - acc: 0.9989 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0055 - acc: 0.9987 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.2800001059076749e-08.\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0056 - acc: 0.9985 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 436s 7ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 269s 4ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0596 - val_acc: 0.9850\n",
      "Test loss: 0.05962823330626734\n",
      "Test accuracy: 0.985\n",
      "Remaining time: 7 days 0 hours 36 minutes 47 seconds\n",
      "\n",
      "Training for activation tanh with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.5480 - acc: 0.8511 - val_loss: 0.3025 - val_acc: 0.9102\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.2993 - acc: 0.9119 - val_loss: 0.2549 - val_acc: 0.9276\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.2635 - acc: 0.9224 - val_loss: 0.2315 - val_acc: 0.9331\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.2338 - acc: 0.9318 - val_loss: 0.2030 - val_acc: 0.9425\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.2067 - acc: 0.9410 - val_loss: 0.1840 - val_acc: 0.9477\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1827 - acc: 0.9480 - val_loss: 0.1621 - val_acc: 0.9550\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1610 - acc: 0.9536 - val_loss: 0.1415 - val_acc: 0.9605\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1437 - acc: 0.9591 - val_loss: 0.1253 - val_acc: 0.9643\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1287 - acc: 0.9635 - val_loss: 0.1156 - val_acc: 0.9672\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1171 - acc: 0.9668 - val_loss: 0.1079 - val_acc: 0.9691\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1067 - acc: 0.9695 - val_loss: 0.0966 - val_acc: 0.9722\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0987 - acc: 0.9716 - val_loss: 0.0858 - val_acc: 0.9758\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0930 - acc: 0.9733 - val_loss: 0.0856 - val_acc: 0.9746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 173s 3ms/step - loss: 0.0858 - acc: 0.9750 - val_loss: 0.0767 - val_acc: 0.9777\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0816 - acc: 0.9766 - val_loss: 0.0733 - val_acc: 0.9783\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0777 - acc: 0.9777 - val_loss: 0.0696 - val_acc: 0.9795\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0731 - acc: 0.9791 - val_loss: 0.0657 - val_acc: 0.9812\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0713 - acc: 0.9794 - val_loss: 0.0646 - val_acc: 0.9806\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0672 - acc: 0.9804 - val_loss: 0.0624 - val_acc: 0.9805\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0655 - acc: 0.9812 - val_loss: 0.0602 - val_acc: 0.9816\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 177s 3ms/step - loss: 0.0625 - acc: 0.9820 - val_loss: 0.0602 - val_acc: 0.9802\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0603 - acc: 0.9828 - val_loss: 0.0601 - val_acc: 0.9799\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0588 - acc: 0.9834 - val_loss: 0.0577 - val_acc: 0.9818\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0571 - acc: 0.9837 - val_loss: 0.0548 - val_acc: 0.9821\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.0560 - acc: 0.9833 - val_loss: 0.0536 - val_acc: 0.9829\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0541 - acc: 0.9839 - val_loss: 0.0542 - val_acc: 0.9828\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0523 - acc: 0.9840 - val_loss: 0.0548 - val_acc: 0.9827\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0516 - acc: 0.9849 - val_loss: 0.0523 - val_acc: 0.9828\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0498 - acc: 0.9856 - val_loss: 0.0496 - val_acc: 0.9839\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0486 - acc: 0.9859 - val_loss: 0.0501 - val_acc: 0.9843\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0472 - acc: 0.9863 - val_loss: 0.0493 - val_acc: 0.9839\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0465 - acc: 0.9866 - val_loss: 0.0486 - val_acc: 0.9839\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0453 - acc: 0.9866 - val_loss: 0.0494 - val_acc: 0.9842\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0449 - acc: 0.9866 - val_loss: 0.0487 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0423 - acc: 0.9878 - val_loss: 0.0473 - val_acc: 0.9840\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0417 - acc: 0.9883 - val_loss: 0.0473 - val_acc: 0.9843\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0416 - acc: 0.9881 - val_loss: 0.0475 - val_acc: 0.9844\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0410 - acc: 0.9885 - val_loss: 0.0468 - val_acc: 0.9845\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0413 - acc: 0.9879 - val_loss: 0.0469 - val_acc: 0.9848\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0403 - acc: 0.9886 - val_loss: 0.0470 - val_acc: 0.9843\n",
      "Test loss: 0.04701956300488673\n",
      "Test accuracy: 0.9843\n",
      "Remaining time: 6 days 19 hours 04 minutes 58 seconds\n",
      "\n",
      "Training for activation tanh with optimizer Adagrad\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.1896 - acc: 0.9449 - val_loss: 0.0907 - val_acc: 0.9738\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0790 - acc: 0.9771 - val_loss: 0.0670 - val_acc: 0.9785\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0601 - acc: 0.9820 - val_loss: 0.0586 - val_acc: 0.9811\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0514 - acc: 0.9848 - val_loss: 0.0561 - val_acc: 0.9812\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0450 - acc: 0.9866 - val_loss: 0.0516 - val_acc: 0.9826\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0409 - acc: 0.9877 - val_loss: 0.0500 - val_acc: 0.9825\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 207s 3ms/step - loss: 0.0373 - acc: 0.9885 - val_loss: 0.0487 - val_acc: 0.9844\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 200s 3ms/step - loss: 0.0340 - acc: 0.9902 - val_loss: 0.0513 - val_acc: 0.9836\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0327 - acc: 0.9903 - val_loss: 0.0464 - val_acc: 0.9844\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0300 - acc: 0.9910 - val_loss: 0.0469 - val_acc: 0.9847\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0283 - acc: 0.9916 - val_loss: 0.0496 - val_acc: 0.9842\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0272 - acc: 0.9919 - val_loss: 0.0478 - val_acc: 0.9849\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0256 - acc: 0.9923 - val_loss: 0.0462 - val_acc: 0.9848\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0244 - acc: 0.9928 - val_loss: 0.0466 - val_acc: 0.9856\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0235 - acc: 0.9932 - val_loss: 0.0473 - val_acc: 0.9849\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0222 - acc: 0.9936 - val_loss: 0.0470 - val_acc: 0.9852\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0212 - acc: 0.9936 - val_loss: 0.0465 - val_acc: 0.9851\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0203 - acc: 0.9941 - val_loss: 0.0464 - val_acc: 0.9854\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0179 - acc: 0.9950 - val_loss: 0.0461 - val_acc: 0.9852\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0180 - acc: 0.9949 - val_loss: 0.0460 - val_acc: 0.9855\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.0460 - val_acc: 0.9857\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0171 - acc: 0.9955 - val_loss: 0.0460 - val_acc: 0.9856\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0171 - acc: 0.9952 - val_loss: 0.0463 - val_acc: 0.9859\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0167 - acc: 0.9953 - val_loss: 0.0463 - val_acc: 0.9861\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0165 - acc: 0.9957 - val_loss: 0.0461 - val_acc: 0.9858\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0171 - acc: 0.9954 - val_loss: 0.0458 - val_acc: 0.9859\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0168 - acc: 0.9953 - val_loss: 0.0459 - val_acc: 0.9862\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.0459 - val_acc: 0.9855\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 29/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0164 - acc: 0.9956 - val_loss: 0.0459 - val_acc: 0.9858\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0159 - acc: 0.9962 - val_loss: 0.0460 - val_acc: 0.9861\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0163 - acc: 0.9958 - val_loss: 0.0459 - val_acc: 0.9861\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0160 - acc: 0.9957 - val_loss: 0.0460 - val_acc: 0.9862\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0159 - acc: 0.9957 - val_loss: 0.0459 - val_acc: 0.9858\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0159 - acc: 0.9960 - val_loss: 0.0459 - val_acc: 0.9859\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0158 - acc: 0.9957 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0163 - acc: 0.9958 - val_loss: 0.0459 - val_acc: 0.9859\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0160 - acc: 0.9958 - val_loss: 0.0459 - val_acc: 0.9859\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0163 - acc: 0.9956 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0161 - acc: 0.9959 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0159 - acc: 0.9958 - val_loss: 0.0459 - val_acc: 0.9860\n",
      "Test loss: 0.045940684078325286\n",
      "Test accuracy: 0.986\n",
      "Remaining time: 6 days 14 hours 17 minutes 15 seconds\n",
      "\n",
      "Training for activation tanh with optimizer Adadelta\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.1888 - acc: 0.9437 - val_loss: 0.0898 - val_acc: 0.9725\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0763 - acc: 0.9770 - val_loss: 0.0708 - val_acc: 0.9776\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0610 - acc: 0.9814 - val_loss: 0.0553 - val_acc: 0.9816\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0488 - acc: 0.9854 - val_loss: 0.0588 - val_acc: 0.9832\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0416 - acc: 0.9868 - val_loss: 0.0537 - val_acc: 0.9846\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0371 - acc: 0.9886 - val_loss: 0.0532 - val_acc: 0.9851\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 0.0693 - val_acc: 0.9816\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0604 - val_acc: 0.9837\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0222 - acc: 0.9929 - val_loss: 0.0576 - val_acc: 0.9847\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0198 - acc: 0.9936 - val_loss: 0.0611 - val_acc: 0.9841\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.2.\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0114 - acc: 0.9963 - val_loss: 0.0530 - val_acc: 0.9867\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0089 - acc: 0.9972 - val_loss: 0.0505 - val_acc: 0.9861\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0520 - val_acc: 0.9861\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0072 - acc: 0.9978 - val_loss: 0.0506 - val_acc: 0.9868\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0497 - val_acc: 0.9861\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0061 - acc: 0.9984 - val_loss: 0.0500 - val_acc: 0.9862\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0056 - acc: 0.9986 - val_loss: 0.0499 - val_acc: 0.9869\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0502 - val_acc: 0.9868\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0055 - acc: 0.9986 - val_loss: 0.0500 - val_acc: 0.9870\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0504 - val_acc: 0.9869\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0504 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0505 - val_acc: 0.9871\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0054 - acc: 0.9987 - val_loss: 0.0505 - val_acc: 0.9871\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0054 - acc: 0.9985 - val_loss: 0.0505 - val_acc: 0.9871\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0505 - val_acc: 0.9871\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.0506 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0506 - val_acc: 0.9868\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0506 - val_acc: 0.9869\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0051 - acc: 0.9988 - val_loss: 0.0506 - val_acc: 0.9869\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0049 - acc: 0.9988 - val_loss: 0.0506 - val_acc: 0.9869\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0048 - acc: 0.9991 - val_loss: 0.0505 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0050 - acc: 0.9988 - val_loss: 0.0505 - val_acc: 0.9869\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0505 - val_acc: 0.9869\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0053 - acc: 0.9987 - val_loss: 0.0505 - val_acc: 0.9869\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0505 - val_acc: 0.9870\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0054 - acc: 0.9986 - val_loss: 0.0505 - val_acc: 0.9870\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.399999256245792e-05.\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0505 - val_acc: 0.9870\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0047 - acc: 0.9990 - val_loss: 0.0505 - val_acc: 0.9870\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0050 - acc: 0.9989 - val_loss: 0.0505 - val_acc: 0.9870\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0052 - acc: 0.9987 - val_loss: 0.0505 - val_acc: 0.9870\n",
      "Test loss: 0.05052222840050063\n",
      "Test accuracy: 0.987\n",
      "Remaining time: 6 days 10 hours 15 minutes 01 seconds\n",
      "\n",
      "Training for activation tanh with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.2087 - acc: 0.9398 - val_loss: 0.0844 - val_acc: 0.9744\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0775 - acc: 0.9766 - val_loss: 0.0603 - val_acc: 0.9816\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0598 - acc: 0.9820 - val_loss: 0.0586 - val_acc: 0.9801\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0477 - acc: 0.9854 - val_loss: 0.0468 - val_acc: 0.9846\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0417 - acc: 0.9871 - val_loss: 0.0503 - val_acc: 0.9850\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0361 - acc: 0.9884 - val_loss: 0.0538 - val_acc: 0.9823\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0325 - acc: 0.9895 - val_loss: 0.0585 - val_acc: 0.9828\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0272 - acc: 0.9911 - val_loss: 0.0578 - val_acc: 0.9841\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0252 - acc: 0.9917 - val_loss: 0.0607 - val_acc: 0.9826\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0155 - acc: 0.9951 - val_loss: 0.0489 - val_acc: 0.9862\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0130 - acc: 0.9960 - val_loss: 0.0489 - val_acc: 0.9858\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0475 - val_acc: 0.9867\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0113 - acc: 0.9968 - val_loss: 0.0485 - val_acc: 0.9861\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0469 - val_acc: 0.9866\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0476 - val_acc: 0.9861\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0102 - acc: 0.9970 - val_loss: 0.0464 - val_acc: 0.9864\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.0469 - val_acc: 0.9864\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0470 - val_acc: 0.9863\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.0474 - val_acc: 0.9865\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0084 - acc: 0.9979 - val_loss: 0.0477 - val_acc: 0.9866\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0474 - val_acc: 0.9868\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0475 - val_acc: 0.9866\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0082 - acc: 0.9980 - val_loss: 0.0475 - val_acc: 0.9866\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0475 - val_acc: 0.9866\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0075 - acc: 0.9983 - val_loss: 0.0476 - val_acc: 0.9864\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0077 - acc: 0.9980 - val_loss: 0.0476 - val_acc: 0.9864\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0077 - acc: 0.9982 - val_loss: 0.0476 - val_acc: 0.9864\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0476 - val_acc: 0.9866\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0081 - acc: 0.9979 - val_loss: 0.0476 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0081 - acc: 0.9980 - val_loss: 0.0476 - val_acc: 0.9866\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0080 - acc: 0.9983 - val_loss: 0.0476 - val_acc: 0.9866\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0079 - acc: 0.9981 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0079 - acc: 0.9983 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0083 - acc: 0.9978 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0080 - acc: 0.9982 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0079 - acc: 0.9982 - val_loss: 0.0476 - val_acc: 0.9865\n",
      "Test loss: 0.04758072068094116\n",
      "Test accuracy: 0.9865\n",
      "Remaining time: 6 days 6 hours 30 minutes 16 seconds\n",
      "\n",
      "Training for activation tanh with optimizer Nadam\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.1716 - acc: 0.9486 - val_loss: 0.1061 - val_acc: 0.9680\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0877 - acc: 0.9743 - val_loss: 0.1093 - val_acc: 0.9683\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0727 - acc: 0.9784 - val_loss: 0.0688 - val_acc: 0.9803\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0683 - acc: 0.9796 - val_loss: 0.0707 - val_acc: 0.9800\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0636 - acc: 0.9813 - val_loss: 0.0786 - val_acc: 0.9777\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0572 - acc: 0.9824 - val_loss: 0.1046 - val_acc: 0.9760\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0547 - acc: 0.9837 - val_loss: 0.0983 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0256 - acc: 0.9919 - val_loss: 0.0673 - val_acc: 0.9835\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0168 - acc: 0.9945 - val_loss: 0.0692 - val_acc: 0.9843\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0148 - acc: 0.9950 - val_loss: 0.0735 - val_acc: 0.9829\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0138 - acc: 0.9955 - val_loss: 0.0775 - val_acc: 0.9823\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0114 - acc: 0.9961 - val_loss: 0.0742 - val_acc: 0.9831\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0108 - acc: 0.9963 - val_loss: 0.0765 - val_acc: 0.9831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0746 - val_acc: 0.9844\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0754 - val_acc: 0.9839\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.0767 - val_acc: 0.9836\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0765 - val_acc: 0.9841\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0789 - val_acc: 0.9832\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0058 - acc: 0.9981 - val_loss: 0.0777 - val_acc: 0.9834\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.0774 - val_acc: 0.9834\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0772 - val_acc: 0.9832\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0771 - val_acc: 0.9833\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0053 - acc: 0.9983 - val_loss: 0.0772 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0052 - acc: 0.9983 - val_loss: 0.0772 - val_acc: 0.9839\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0050 - acc: 0.9986 - val_loss: 0.0772 - val_acc: 0.9839\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0773 - val_acc: 0.9837\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0049 - acc: 0.9986 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0048 - acc: 0.9986 - val_loss: 0.0774 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0774 - val_acc: 0.9836\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0774 - val_acc: 0.9836\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0051 - acc: 0.9984 - val_loss: 0.0774 - val_acc: 0.9836\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0774 - val_acc: 0.9836\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0050 - acc: 0.9984 - val_loss: 0.0774 - val_acc: 0.9836\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0047 - acc: 0.9987 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0047 - acc: 0.9986 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 2.5600002118153498e-08.\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0045 - acc: 0.9988 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0774 - val_acc: 0.9837\n",
      "Test loss: 0.07741822412975694\n",
      "Test accuracy: 0.9837\n",
      "Remaining time: 6 days 3 hours 07 minutes 32 seconds\n",
      "\n",
      "Training for activation relu with optimizer rmsp\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.1585 - acc: 0.9534 - val_loss: 0.0536 - val_acc: 0.9836\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0568 - acc: 0.9835 - val_loss: 0.0405 - val_acc: 0.9856\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0454 - acc: 0.9870 - val_loss: 0.0389 - val_acc: 0.9871\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0387 - acc: 0.9886 - val_loss: 0.0326 - val_acc: 0.9892\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0343 - acc: 0.9898 - val_loss: 0.0350 - val_acc: 0.9885\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0310 - acc: 0.9910 - val_loss: 0.0332 - val_acc: 0.9895\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0294 - acc: 0.9913 - val_loss: 0.0349 - val_acc: 0.9897\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0272 - acc: 0.9924 - val_loss: 0.0297 - val_acc: 0.9911\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0253 - acc: 0.9927 - val_loss: 0.0315 - val_acc: 0.9897\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0242 - acc: 0.9930 - val_loss: 0.0292 - val_acc: 0.9910\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0230 - acc: 0.9930 - val_loss: 0.0297 - val_acc: 0.9909\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0221 - acc: 0.9934 - val_loss: 0.0308 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0142 - acc: 0.9956 - val_loss: 0.0290 - val_acc: 0.9909\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0136 - acc: 0.9961 - val_loss: 0.0301 - val_acc: 0.9910\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0131 - acc: 0.9960 - val_loss: 0.0304 - val_acc: 0.9906\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0131 - acc: 0.9962 - val_loss: 0.0312 - val_acc: 0.9906\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0133 - acc: 0.9960 - val_loss: 0.0297 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0115 - acc: 0.9966 - val_loss: 0.0284 - val_acc: 0.9919\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0116 - acc: 0.9967 - val_loss: 0.0288 - val_acc: 0.9916\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0116 - acc: 0.9964 - val_loss: 0.0291 - val_acc: 0.9915\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0114 - acc: 0.9969 - val_loss: 0.0294 - val_acc: 0.9920\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0121 - acc: 0.9965 - val_loss: 0.0294 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0108 - acc: 0.9971 - val_loss: 0.0294 - val_acc: 0.9916\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0110 - acc: 0.9969 - val_loss: 0.0294 - val_acc: 0.9914\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0110 - acc: 0.9968 - val_loss: 0.0292 - val_acc: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0109 - acc: 0.9966 - val_loss: 0.0292 - val_acc: 0.9915\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0111 - acc: 0.9968 - val_loss: 0.0292 - val_acc: 0.9916\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0108 - acc: 0.9970 - val_loss: 0.0292 - val_acc: 0.9915\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0110 - acc: 0.9967 - val_loss: 0.0293 - val_acc: 0.9914\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0112 - acc: 0.9967 - val_loss: 0.0292 - val_acc: 0.9915\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0110 - acc: 0.9970 - val_loss: 0.0293 - val_acc: 0.9914\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0114 - acc: 0.9968 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0106 - acc: 0.9968 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0107 - acc: 0.9970 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-08.\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0111 - acc: 0.9969 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0107 - acc: 0.9969 - val_loss: 0.0293 - val_acc: 0.9915\n",
      "Test loss: 0.02929145397132161\n",
      "Test accuracy: 0.9915\n",
      "Remaining time: 5 days 23 hours 24 minutes 39 seconds\n",
      "\n",
      "Training for activation relu with optimizer adam\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.1608 - acc: 0.9527 - val_loss: 0.0545 - val_acc: 0.9812\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0560 - acc: 0.9829 - val_loss: 0.0439 - val_acc: 0.9865\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0405 - acc: 0.9876 - val_loss: 0.0487 - val_acc: 0.9848\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0321 - acc: 0.9901 - val_loss: 0.0391 - val_acc: 0.9888\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0259 - acc: 0.9917 - val_loss: 0.0417 - val_acc: 0.9869\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0225 - acc: 0.9925 - val_loss: 0.0411 - val_acc: 0.9880\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0177 - acc: 0.9943 - val_loss: 0.0416 - val_acc: 0.9882\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0152 - acc: 0.9948 - val_loss: 0.0407 - val_acc: 0.9893\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.0139 - acc: 0.9955 - val_loss: 0.0399 - val_acc: 0.9896\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0444 - val_acc: 0.9883\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0107 - acc: 0.9960 - val_loss: 0.0433 - val_acc: 0.9889\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0456 - val_acc: 0.9885\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0093 - acc: 0.9967 - val_loss: 0.0488 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0037 - acc: 0.9988 - val_loss: 0.0433 - val_acc: 0.9902\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0458 - val_acc: 0.9900\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0437 - val_acc: 0.9909\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0455 - val_acc: 0.9907\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0480 - val_acc: 0.9905\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0459 - val_acc: 0.9912\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0458 - val_acc: 0.9914\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0460 - val_acc: 0.9910\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0480 - val_acc: 0.9908\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0478 - val_acc: 0.9902\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 9.2653e-04 - acc: 0.9998 - val_loss: 0.0498 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 7.1191e-04 - acc: 0.9999 - val_loss: 0.0491 - val_acc: 0.9904\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 6.8091e-04 - acc: 0.9999 - val_loss: 0.0503 - val_acc: 0.9899\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 6.6510e-04 - acc: 0.9999 - val_loss: 0.0511 - val_acc: 0.9903\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 6.0263e-04 - acc: 0.9999 - val_loss: 0.0506 - val_acc: 0.9905\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 5.5073e-04 - acc: 1.0000 - val_loss: 0.0512 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 6.1912e-04 - acc: 0.9999 - val_loss: 0.0512 - val_acc: 0.9902\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 6.3426e-04 - acc: 0.9999 - val_loss: 0.0505 - val_acc: 0.9902\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 5.2638e-04 - acc: 1.0000 - val_loss: 0.0507 - val_acc: 0.9902\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 6.0656e-04 - acc: 0.9999 - val_loss: 0.0505 - val_acc: 0.9903\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 5.1948e-04 - acc: 0.9999 - val_loss: 0.0505 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 5.3768e-04 - acc: 0.9999 - val_loss: 0.0505 - val_acc: 0.9905\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 5.4175e-04 - acc: 0.9999 - val_loss: 0.0505 - val_acc: 0.9904\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 5.8750e-04 - acc: 0.9999 - val_loss: 0.0504 - val_acc: 0.9901\n",
      "Epoch 38/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 186s 3ms/step - loss: 5.4193e-04 - acc: 0.9999 - val_loss: 0.0504 - val_acc: 0.9902\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 5.5093e-04 - acc: 0.9999 - val_loss: 0.0504 - val_acc: 0.9902\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 6.5745e-04 - acc: 0.9999 - val_loss: 0.0504 - val_acc: 0.9902\n",
      "Test loss: 0.050381223035747505\n",
      "Test accuracy: 0.9902\n",
      "Remaining time: 5 days 20 hours 06 minutes 01 seconds\n",
      "\n",
      "Training for activation relu with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.5748 - acc: 0.8377 - val_loss: 0.3136 - val_acc: 0.9097\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.3269 - acc: 0.9030 - val_loss: 0.2810 - val_acc: 0.9186\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.2622 - acc: 0.9241 - val_loss: 0.2020 - val_acc: 0.9428\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1949 - acc: 0.9450 - val_loss: 0.1459 - val_acc: 0.9585\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1431 - acc: 0.9595 - val_loss: 0.1079 - val_acc: 0.9694\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1157 - acc: 0.9668 - val_loss: 0.0868 - val_acc: 0.9757\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.1004 - acc: 0.9710 - val_loss: 0.0759 - val_acc: 0.9781\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0887 - acc: 0.9738 - val_loss: 0.0683 - val_acc: 0.9793\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0805 - acc: 0.9766 - val_loss: 0.0637 - val_acc: 0.9801\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0756 - acc: 0.9778 - val_loss: 0.0625 - val_acc: 0.9812\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0719 - acc: 0.9783 - val_loss: 0.0568 - val_acc: 0.9830\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0677 - acc: 0.9798 - val_loss: 0.0533 - val_acc: 0.9836\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0650 - acc: 0.9802 - val_loss: 0.0532 - val_acc: 0.9833\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0617 - acc: 0.9818 - val_loss: 0.0507 - val_acc: 0.9839\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0602 - acc: 0.9818 - val_loss: 0.0520 - val_acc: 0.9833\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0560 - acc: 0.9828 - val_loss: 0.0481 - val_acc: 0.9842\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0566 - acc: 0.9826 - val_loss: 0.0507 - val_acc: 0.9843\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0546 - acc: 0.9835 - val_loss: 0.0467 - val_acc: 0.9852\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0530 - acc: 0.9835 - val_loss: 0.0458 - val_acc: 0.9854\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0523 - acc: 0.9840 - val_loss: 0.0438 - val_acc: 0.9855\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0489 - acc: 0.9854 - val_loss: 0.0455 - val_acc: 0.9861\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0488 - acc: 0.9849 - val_loss: 0.0438 - val_acc: 0.9848\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0465 - acc: 0.9857 - val_loss: 0.0457 - val_acc: 0.9861\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0457 - acc: 0.9864 - val_loss: 0.0435 - val_acc: 0.9854\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0440 - acc: 0.9865 - val_loss: 0.0421 - val_acc: 0.9857\n",
      "\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0412 - acc: 0.9874 - val_loss: 0.0424 - val_acc: 0.9859\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0402 - acc: 0.9882 - val_loss: 0.0414 - val_acc: 0.9864\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0408 - acc: 0.9874 - val_loss: 0.0423 - val_acc: 0.9857\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 179s 3ms/step - loss: 0.0398 - acc: 0.9879 - val_loss: 0.0414 - val_acc: 0.9865\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0391 - acc: 0.9883 - val_loss: 0.0415 - val_acc: 0.9862\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0397 - acc: 0.9884 - val_loss: 0.0406 - val_acc: 0.9866\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0395 - acc: 0.9883 - val_loss: 0.0409 - val_acc: 0.9864\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0389 - acc: 0.9879 - val_loss: 0.0416 - val_acc: 0.9863\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0387 - acc: 0.9880 - val_loss: 0.0420 - val_acc: 0.9862\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0390 - acc: 0.9884 - val_loss: 0.0412 - val_acc: 0.9865\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0382 - acc: 0.9884 - val_loss: 0.0407 - val_acc: 0.9868\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0379 - acc: 0.9887 - val_loss: 0.0407 - val_acc: 0.9867\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0376 - acc: 0.9884 - val_loss: 0.0407 - val_acc: 0.9868\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0383 - acc: 0.9886 - val_loss: 0.0407 - val_acc: 0.9866\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 183s 3ms/step - loss: 0.0375 - acc: 0.9889 - val_loss: 0.0407 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Test loss: 0.040681131174368786\n",
      "Test accuracy: 0.9866\n",
      "Remaining time: 5 days 16 hours 46 minutes 00 seconds\n",
      "\n",
      "Training for activation relu with optimizer Adagrad\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 184s 3ms/step - loss: 0.1272 - acc: 0.9617 - val_loss: 0.0569 - val_acc: 0.9835\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0555 - acc: 0.9836 - val_loss: 0.0437 - val_acc: 0.9860\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0443 - acc: 0.9866 - val_loss: 0.0384 - val_acc: 0.9878\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0366 - acc: 0.9891 - val_loss: 0.0403 - val_acc: 0.9874\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0324 - acc: 0.9903 - val_loss: 0.0362 - val_acc: 0.9875\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0288 - acc: 0.9913 - val_loss: 0.0355 - val_acc: 0.9878\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0260 - acc: 0.9924 - val_loss: 0.0348 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0019999999552965165.\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0215 - acc: 0.9938 - val_loss: 0.0335 - val_acc: 0.9887\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0214 - acc: 0.9939 - val_loss: 0.0335 - val_acc: 0.9890\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0207 - acc: 0.9940 - val_loss: 0.0337 - val_acc: 0.9886\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0201 - acc: 0.9940 - val_loss: 0.0333 - val_acc: 0.9889\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0199 - acc: 0.9943 - val_loss: 0.0335 - val_acc: 0.9888\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0197 - acc: 0.9941 - val_loss: 0.0333 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0003999999724328518.\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0192 - acc: 0.9944 - val_loss: 0.0333 - val_acc: 0.9890\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0191 - acc: 0.9944 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0335 - val_acc: 0.9889\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.999999215826393e-05.\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0185 - acc: 0.9948 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0188 - acc: 0.9949 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0187 - acc: 0.9948 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0189 - acc: 0.9946 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0186 - acc: 0.9952 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.599999814061448e-05.\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0188 - acc: 0.9948 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0187 - acc: 0.9944 - val_loss: 0.0334 - val_acc: 0.9888\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0186 - acc: 0.9948 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0188 - acc: 0.9946 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.199999628122896e-06.\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0184 - acc: 0.9949 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0184 - acc: 0.9946 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0183 - acc: 0.9949 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0186 - acc: 0.9947 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.399999165296323e-07.\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0186 - acc: 0.9946 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0190 - acc: 0.9944 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0185 - acc: 0.9949 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0187 - acc: 0.9945 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0188 - acc: 0.9947 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.2799998785339995e-07.\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0187 - acc: 0.9947 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 180s 3ms/step - loss: 0.0188 - acc: 0.9945 - val_loss: 0.0334 - val_acc: 0.9887\n",
      "Test loss: 0.033434533236257266\n",
      "Test accuracy: 0.9887\n",
      "Remaining time: 5 days 13 hours 36 minutes 10 seconds\n",
      "\n",
      "Training for activation relu with optimizer Adadelta\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.1639 - acc: 0.9503 - val_loss: 0.0626 - val_acc: 0.9798\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0604 - acc: 0.9817 - val_loss: 0.0393 - val_acc: 0.9872\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0458 - acc: 0.9862 - val_loss: 0.0405 - val_acc: 0.9871\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0380 - acc: 0.9885 - val_loss: 0.0360 - val_acc: 0.9874\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0335 - acc: 0.9904 - val_loss: 0.0312 - val_acc: 0.9898\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0289 - acc: 0.9914 - val_loss: 0.0327 - val_acc: 0.9896\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0258 - acc: 0.9923 - val_loss: 0.0313 - val_acc: 0.9901\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0233 - acc: 0.9932 - val_loss: 0.0291 - val_acc: 0.9903\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0207 - acc: 0.9939 - val_loss: 0.0303 - val_acc: 0.9899\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0198 - acc: 0.9941 - val_loss: 0.0326 - val_acc: 0.9899\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0177 - acc: 0.9945 - val_loss: 0.0324 - val_acc: 0.9901\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0154 - acc: 0.9955 - val_loss: 0.0321 - val_acc: 0.9907\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0151 - acc: 0.9955 - val_loss: 0.0374 - val_acc: 0.9880\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0136 - acc: 0.9960 - val_loss: 0.0363 - val_acc: 0.9907\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0134 - acc: 0.9962 - val_loss: 0.0343 - val_acc: 0.9899\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0118 - acc: 0.9964 - val_loss: 0.0360 - val_acc: 0.9898\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.2.\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.0346 - val_acc: 0.9907\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0078 - acc: 0.9979 - val_loss: 0.0332 - val_acc: 0.9909\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0072 - acc: 0.9980 - val_loss: 0.0355 - val_acc: 0.9908\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0355 - val_acc: 0.9905\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0356 - val_acc: 0.9908\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0069 - acc: 0.9981 - val_loss: 0.0362 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.04000000059604645.\n",
      "Epoch 23/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0060 - acc: 0.9983 - val_loss: 0.0360 - val_acc: 0.9905\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0362 - val_acc: 0.9908\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0358 - val_acc: 0.9907\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0064 - acc: 0.9982 - val_loss: 0.0360 - val_acc: 0.9907\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0059 - acc: 0.9984 - val_loss: 0.0360 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.007999999821186066.\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0060 - acc: 0.9984 - val_loss: 0.0361 - val_acc: 0.9905\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0063 - acc: 0.9984 - val_loss: 0.0361 - val_acc: 0.9909\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0362 - val_acc: 0.9907\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.0362 - val_acc: 0.9908\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 0.0363 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0015999998897314072.\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0363 - val_acc: 0.9909\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.0363 - val_acc: 0.9909\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0363 - val_acc: 0.9909\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0063 - acc: 0.9983 - val_loss: 0.0363 - val_acc: 0.9909\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0362 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.0003199999686330557.\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0061 - acc: 0.9985 - val_loss: 0.0363 - val_acc: 0.9909\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0062 - acc: 0.9983 - val_loss: 0.0362 - val_acc: 0.9910\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0059 - acc: 0.9985 - val_loss: 0.0362 - val_acc: 0.9910\n",
      "Test loss: 0.036246989504407065\n",
      "Test accuracy: 0.991\n",
      "Remaining time: 5 days 10 hours 51 minutes 35 seconds\n",
      "\n",
      "Training for activation relu with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.1714 - acc: 0.9483 - val_loss: 0.0620 - val_acc: 0.9799\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0648 - acc: 0.9808 - val_loss: 0.0489 - val_acc: 0.9842\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0498 - acc: 0.9847 - val_loss: 0.0405 - val_acc: 0.9868\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0408 - acc: 0.9873 - val_loss: 0.0371 - val_acc: 0.9871\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0347 - acc: 0.9901 - val_loss: 0.0363 - val_acc: 0.9876\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0312 - acc: 0.9908 - val_loss: 0.0358 - val_acc: 0.9884\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 185s 3ms/step - loss: 0.0263 - acc: 0.9922 - val_loss: 0.0339 - val_acc: 0.9889\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0227 - acc: 0.9928 - val_loss: 0.0361 - val_acc: 0.9884\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0207 - acc: 0.9936 - val_loss: 0.0348 - val_acc: 0.9886\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0176 - acc: 0.9949 - val_loss: 0.0379 - val_acc: 0.9880\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0162 - acc: 0.9951 - val_loss: 0.0355 - val_acc: 0.9886\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0113 - acc: 0.9966 - val_loss: 0.0336 - val_acc: 0.9891\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0097 - acc: 0.9973 - val_loss: 0.0342 - val_acc: 0.9896\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.0343 - val_acc: 0.9898\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0351 - val_acc: 0.9895\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0090 - acc: 0.9976 - val_loss: 0.0344 - val_acc: 0.9896\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0085 - acc: 0.9977 - val_loss: 0.0367 - val_acc: 0.9897\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0084 - acc: 0.9976 - val_loss: 0.0364 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0076 - acc: 0.9980 - val_loss: 0.0359 - val_acc: 0.9893\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0361 - val_acc: 0.9895\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0363 - val_acc: 0.9892\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0071 - acc: 0.9983 - val_loss: 0.0361 - val_acc: 0.9894\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0073 - acc: 0.9982 - val_loss: 0.0361 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0075 - acc: 0.9981 - val_loss: 0.0362 - val_acc: 0.9894\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0363 - val_acc: 0.9894\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0362 - val_acc: 0.9896\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0362 - val_acc: 0.9895\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0363 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0363 - val_acc: 0.9894\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0363 - val_acc: 0.9894\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0363 - val_acc: 0.9894\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9894\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 0.0067 - acc: 0.9983 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0072 - acc: 0.9981 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 35/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0070 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0069 - acc: 0.9983 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0069 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 198s 3ms/step - loss: 0.0072 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0071 - acc: 0.9982 - val_loss: 0.0364 - val_acc: 0.9893\n",
      "Test loss: 0.036387057847474716\n",
      "Test accuracy: 0.9893\n",
      "Remaining time: 5 days 8 hours 08 minutes 53 seconds\n",
      "\n",
      "Training for activation relu with optimizer Nadam\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.1335 - acc: 0.9600 - val_loss: 0.0484 - val_acc: 0.9846\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 192s 3ms/step - loss: 0.0501 - acc: 0.9845 - val_loss: 0.0417 - val_acc: 0.9870\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0366 - acc: 0.9883 - val_loss: 0.0387 - val_acc: 0.9883\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0285 - acc: 0.9909 - val_loss: 0.0440 - val_acc: 0.9864\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0231 - acc: 0.9923 - val_loss: 0.0344 - val_acc: 0.9892\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0199 - acc: 0.9934 - val_loss: 0.0518 - val_acc: 0.9863\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0160 - acc: 0.9944 - val_loss: 0.0445 - val_acc: 0.9894\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0132 - acc: 0.9958 - val_loss: 0.0397 - val_acc: 0.9889\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0128 - acc: 0.9958 - val_loss: 0.0436 - val_acc: 0.9889\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 191s 3ms/step - loss: 0.0118 - acc: 0.9961 - val_loss: 0.0482 - val_acc: 0.9894\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0115 - acc: 0.9960 - val_loss: 0.0533 - val_acc: 0.9883\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 0.0043 - acc: 0.9987 - val_loss: 0.0446 - val_acc: 0.9905\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 189s 3ms/step - loss: 0.0026 - acc: 0.9992 - val_loss: 0.0457 - val_acc: 0.9908\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 190s 3ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0483 - val_acc: 0.9905\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0487 - val_acc: 0.9912\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0489 - val_acc: 0.9908\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0522 - val_acc: 0.9900\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0502 - val_acc: 0.9903\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0533 - val_acc: 0.9904\n",
      "\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 8.000000379979611e-05.\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 8.2786e-04 - acc: 0.9998 - val_loss: 0.0535 - val_acc: 0.9904\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 7.7562e-04 - acc: 0.9998 - val_loss: 0.0541 - val_acc: 0.9906\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.9776e-04 - acc: 0.9999 - val_loss: 0.0530 - val_acc: 0.9907\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 7.4726e-04 - acc: 0.9998 - val_loss: 0.0538 - val_acc: 0.9907\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 6.8702e-04 - acc: 0.9998 - val_loss: 0.0527 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.6000001050997525e-05.\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.6658e-04 - acc: 0.9999 - val_loss: 0.0526 - val_acc: 0.9906\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.6626e-04 - acc: 0.9999 - val_loss: 0.0525 - val_acc: 0.9908\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.0660e-04 - acc: 0.9999 - val_loss: 0.0523 - val_acc: 0.9907\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.2205e-04 - acc: 0.9999 - val_loss: 0.0525 - val_acc: 0.9909\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.4991e-04 - acc: 0.9999 - val_loss: 0.0532 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 3.2000003557186575e-06.\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.8236e-04 - acc: 0.9999 - val_loss: 0.0531 - val_acc: 0.9910\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 4.8665e-04 - acc: 0.9999 - val_loss: 0.0531 - val_acc: 0.9908\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 4.5014e-04 - acc: 0.9999 - val_loss: 0.0531 - val_acc: 0.9910\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 186s 3ms/step - loss: 4.9314e-04 - acc: 0.9999 - val_loss: 0.0531 - val_acc: 0.9910\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 4.6150e-04 - acc: 1.0000 - val_loss: 0.0531 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 6.400000529538374e-07.\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.1672e-04 - acc: 0.9999 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 4.6171e-04 - acc: 0.9999 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 4.6452e-04 - acc: 1.0000 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 5.4773e-04 - acc: 0.9999 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 188s 3ms/step - loss: 4.7799e-04 - acc: 0.9999 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.280000105907675e-07.\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 193s 3ms/step - loss: 5.6439e-04 - acc: 0.9999 - val_loss: 0.0530 - val_acc: 0.9909\n",
      "Test loss: 0.053001326769592516\n",
      "Test accuracy: 0.9909\n",
      "Remaining time: 5 days 5 hours 29 minutes 48 seconds\n",
      "\n",
      "Training for activation linear with optimizer rmsp\n",
      "------------------------------\n",
      "Experiment 0\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 230s 4ms/step - loss: 0.1872 - acc: 0.9442 - val_loss: 0.0875 - val_acc: 0.9717\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 214s 4ms/step - loss: 0.0844 - acc: 0.9749 - val_loss: 0.0693 - val_acc: 0.9785\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 218s 4ms/step - loss: 0.0699 - acc: 0.9790 - val_loss: 0.0697 - val_acc: 0.9783\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 230s 4ms/step - loss: 0.0596 - acc: 0.9822 - val_loss: 0.0732 - val_acc: 0.9777\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 196s 3ms/step - loss: 0.0552 - acc: 0.9836 - val_loss: 0.0737 - val_acc: 0.9787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 182s 3ms/step - loss: 0.0484 - acc: 0.9849 - val_loss: 0.0704 - val_acc: 0.9798\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 194s 3ms/step - loss: 0.0462 - acc: 0.9854 - val_loss: 0.0809 - val_acc: 0.9761\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 176s 3ms/step - loss: 0.0422 - acc: 0.9870 - val_loss: 0.0698 - val_acc: 0.9804\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 201s 3ms/step - loss: 0.0389 - acc: 0.9881 - val_loss: 0.0846 - val_acc: 0.9776\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 203s 3ms/step - loss: 0.0375 - acc: 0.9888 - val_loss: 0.0730 - val_acc: 0.9804\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0357 - acc: 0.9890 - val_loss: 0.0814 - val_acc: 0.9804\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 211s 4ms/step - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0843 - val_acc: 0.9799\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 195s 3ms/step - loss: 0.0192 - acc: 0.9940 - val_loss: 0.0723 - val_acc: 0.9816\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 181s 3ms/step - loss: 0.0167 - acc: 0.9951 - val_loss: 0.0720 - val_acc: 0.9827\n",
      "Epoch 15/40\n",
      "16320/60000 [=======>......................] - ETA: 2:17 - loss: 0.0169 - acc: 0.9952"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8e73943baa03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m                                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                                 validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1671\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1206\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1208\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1209\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for act in activations:\n",
    "    for opt in optimizers:\n",
    "        print(\"\\nTraining for activation \" + act + \" with optimizer \" + opt)\n",
    "\n",
    "        # Selecting activation function\n",
    "        if act == 'sigmoid':\n",
    "            activation = Activation(keras.activations.sigmoid)\n",
    "        elif act == 'tanh':\n",
    "            activation = Activation(keras.activations.tanh)\n",
    "        elif act == 'relu':\n",
    "            activation = Activation(keras.activations.relu)\n",
    "        elif act == 'linear':\n",
    "            activation = Activation(keras.activations.linear)\n",
    "        elif act == 'elu':\n",
    "            activation = Activation(keras.activations.elu)\n",
    "        elif act == 'softplus':\n",
    "            activation = Activation(keras.activations.softplus)\n",
    "        elif act == 'softsign':\n",
    "            activation = Activation(keras.activations.softsign)\n",
    "        elif act == 'hard_sigmoid':\n",
    "            activation = Activation(keras.activations.hard_sigmoid)\n",
    "        elif act == 'LeakyReLU':\n",
    "            activation = keras.layers.advanced_activations.LeakyReLU()\n",
    "        elif act == 'PReLU':\n",
    "            activation = keras.layers.advanced_activations.PReLU()\n",
    "        elif act == 'ThresholdedReLU':\n",
    "            activation = keras.layers.advanced_activations.ThresholdedReLU(theta=0.7)\n",
    "            \n",
    "\n",
    "        if opt == 'rmsp':\n",
    "            optimizer = keras.optimizers.rmsprop()                \n",
    "        elif opt == 'adam':\n",
    "            optimizer = keras.optimizers.Adam()\n",
    "        elif opt == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD()\n",
    "        elif opt == 'Adagrad':\n",
    "            optimizer = keras.optimizers.Adagrad()\n",
    "        elif opt == 'Adadelta':\n",
    "            optimizer = keras.optimizers.Adadelta()\n",
    "        elif opt == 'Adamax':\n",
    "            optimizer = keras.optimizers.Adamax()\n",
    "        elif opt == 'Nadam':\n",
    "            optimizer = keras.optimizers.Nadam()\n",
    "        \n",
    "        for i in range(experiments):\n",
    "            if add_final_dense:\n",
    "                model_name = 'mnist_cnn_' + act + \"_\" + opt + '_' + str(epochs) + '_' +str(i + start) + '_fd'\n",
    "            else:\n",
    "                model_name = 'mnist_cnn_' + act + \"_\" + opt + '_' + str(epochs) + '_' + str(i + start)\n",
    "            model = Sequential()\n",
    "            model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                             input_shape=input_shape))\n",
    "            \n",
    "            model.add(activation)\n",
    "            model.add(Conv2D(64, kernel_size=(3, 3)))\n",
    "            model.add(activation)\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same'))\n",
    "            model.add(Dropout(0.2))\n",
    "            model.add(Flatten())\n",
    "            if add_final_dense:\n",
    "                model.add(Dense(128))\n",
    "                model.add(activation)\n",
    "                model.add(Dropout(0.2))\n",
    "            model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "            model.compile(loss='categorical_crossentropy',\n",
    "                              optimizer=optimizer,\n",
    "                              metrics=['accuracy'])\n",
    "            \n",
    "            print('-'*30)\n",
    "            print('Experiment', i)\n",
    "\n",
    "            csv_logger = CSVLogger('./logs/%s_%d.csv' % (model_name, units), append=False, separator=';')\n",
    "            reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, verbose=1, mode='auto', epsilon=0.0001, cooldown=2, min_lr=0)\n",
    "#             tb = TensorBoard(log_dir='./tb_logs/' + model_name + '_' + str(units), histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "            history = model.fit(x_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                verbose=1,\n",
    "                                validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "            if not os.path.isdir(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            model_path = os.path.join(save_dir, model_name + \".h5\")\n",
    "#             model.save(model_path)\n",
    "\n",
    "            score = model.evaluate(x_test, y_test, verbose=0)\n",
    "            print('Test loss:', score[0])\n",
    "            print('Test accuracy:', score[1])\n",
    "            t = time.time()\n",
    "            time_diff = t - start_time\n",
    "            counter +=1\n",
    "            rem_items = total_items - counter\n",
    "            total_time = round((total_items / counter) * time_diff)\n",
    "            rem_time = round(total_time - time_diff)\n",
    "            m, s = divmod(rem_time, 60)\n",
    "            h, m = divmod(m, 60)\n",
    "            d, h = divmod(h, 24)\n",
    "            print('Remaining time: %d days %d hours %02d minutes %02d seconds' % (d, h, m, s))\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeLU\n",
    "This one has special requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for activation SeLU with optimizer rmsp\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 270s 5ms/step - loss: 0.2435 - acc: 0.9300 - val_loss: 0.1275 - val_acc: 0.9736\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 269s 4ms/step - loss: 0.1353 - acc: 0.9688 - val_loss: 0.1127 - val_acc: 0.9787\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.1257 - acc: 0.9734 - val_loss: 0.1159 - val_acc: 0.9813\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.1186 - acc: 0.9768 - val_loss: 0.1249 - val_acc: 0.9806\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.1178 - acc: 0.9790 - val_loss: 0.1580 - val_acc: 0.9792\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1067 - acc: 0.9814 - val_loss: 0.1244 - val_acc: 0.9847\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.1090 - acc: 0.9823 - val_loss: 0.1175 - val_acc: 0.9858\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1019 - acc: 0.9840 - val_loss: 0.1717 - val_acc: 0.9791\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1032 - acc: 0.9843 - val_loss: 0.1474 - val_acc: 0.9828\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0955 - acc: 0.9856 - val_loss: 0.1407 - val_acc: 0.9848\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0936 - acc: 0.9860 - val_loss: 0.1407 - val_acc: 0.9848\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0563 - acc: 0.9919 - val_loss: 0.1169 - val_acc: 0.9877\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0509 - acc: 0.9921 - val_loss: 0.1275 - val_acc: 0.9860\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0475 - acc: 0.9928 - val_loss: 0.1167 - val_acc: 0.9876\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0436 - acc: 0.9932 - val_loss: 0.1042 - val_acc: 0.9883\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0380 - acc: 0.9936 - val_loss: 0.1086 - val_acc: 0.9876\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0379 - acc: 0.9936 - val_loss: 0.1129 - val_acc: 0.9873\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0383 - acc: 0.9934 - val_loss: 0.1173 - val_acc: 0.9872\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0364 - acc: 0.9937 - val_loss: 0.1085 - val_acc: 0.9881\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0286 - acc: 0.9951 - val_loss: 0.1056 - val_acc: 0.9884\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0301 - acc: 0.9949 - val_loss: 0.1067 - val_acc: 0.9890\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0297 - acc: 0.9952 - val_loss: 0.1053 - val_acc: 0.9888\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0303 - acc: 0.9950 - val_loss: 0.1046 - val_acc: 0.9887\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0274 - acc: 0.9953 - val_loss: 0.1073 - val_acc: 0.9885\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0278 - acc: 0.9952 - val_loss: 0.1025 - val_acc: 0.9888\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0272 - acc: 0.9955 - val_loss: 0.1026 - val_acc: 0.9884\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0265 - acc: 0.9954 - val_loss: 0.1026 - val_acc: 0.9884\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0294 - acc: 0.9948 - val_loss: 0.1031 - val_acc: 0.9885\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0281 - acc: 0.9953 - val_loss: 0.1028 - val_acc: 0.9888\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0251 - acc: 0.9958 - val_loss: 0.1023 - val_acc: 0.9887\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0268 - acc: 0.9958 - val_loss: 0.1023 - val_acc: 0.9885\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0267 - acc: 0.9957 - val_loss: 0.1023 - val_acc: 0.9886\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0281 - acc: 0.9952 - val_loss: 0.1025 - val_acc: 0.9886\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0266 - acc: 0.9954 - val_loss: 0.1027 - val_acc: 0.9886\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0264 - acc: 0.9958 - val_loss: 0.1027 - val_acc: 0.9887\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0285 - acc: 0.9952 - val_loss: 0.1026 - val_acc: 0.9887\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 241s 4ms/step - loss: 0.0265 - acc: 0.9958 - val_loss: 0.1026 - val_acc: 0.9886\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0271 - acc: 0.9955 - val_loss: 0.1026 - val_acc: 0.9886\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0268 - acc: 0.9953 - val_loss: 0.1026 - val_acc: 0.9885\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0272 - acc: 0.9954 - val_loss: 0.1026 - val_acc: 0.9885\n",
      "Test loss: 0.10260849180980613\n",
      "Test accuracy: 0.9885\n",
      "Remaining time: 6 days 18 hours 40 minutes 30 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.2481 - acc: 0.9298 - val_loss: 0.1383 - val_acc: 0.9714\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.1400 - acc: 0.9677 - val_loss: 0.1080 - val_acc: 0.9796\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.1257 - acc: 0.9739 - val_loss: 0.1291 - val_acc: 0.9797\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1149 - acc: 0.9776 - val_loss: 0.1128 - val_acc: 0.9841\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1129 - acc: 0.9796 - val_loss: 0.1352 - val_acc: 0.9826\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1115 - acc: 0.9808 - val_loss: 0.1397 - val_acc: 0.9821\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.1048 - acc: 0.9828 - val_loss: 0.1209 - val_acc: 0.9850\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1032 - acc: 0.9830 - val_loss: 0.1281 - val_acc: 0.9853\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0964 - acc: 0.9849 - val_loss: 0.1516 - val_acc: 0.9831\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0986 - acc: 0.9855 - val_loss: 0.1479 - val_acc: 0.9839\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0968 - acc: 0.9857 - val_loss: 0.1517 - val_acc: 0.9850\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0941 - acc: 0.9868 - val_loss: 0.1677 - val_acc: 0.9842\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0609 - acc: 0.9910 - val_loss: 0.1191 - val_acc: 0.9876\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0484 - acc: 0.9924 - val_loss: 0.1242 - val_acc: 0.9866\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0447 - acc: 0.9930 - val_loss: 0.1173 - val_acc: 0.9877\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0431 - acc: 0.9932 - val_loss: 0.1217 - val_acc: 0.9872\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0389 - acc: 0.9934 - val_loss: 0.1106 - val_acc: 0.9878\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0379 - acc: 0.9935 - val_loss: 0.1126 - val_acc: 0.9866\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0364 - acc: 0.9938 - val_loss: 0.1216 - val_acc: 0.9866\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0342 - acc: 0.9940 - val_loss: 0.1108 - val_acc: 0.9871\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0332 - acc: 0.9944 - val_loss: 0.1127 - val_acc: 0.9876\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0301 - acc: 0.9951 - val_loss: 0.1102 - val_acc: 0.9878\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0293 - acc: 0.9949 - val_loss: 0.1105 - val_acc: 0.9884\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0292 - acc: 0.9952 - val_loss: 0.1105 - val_acc: 0.9885\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0280 - acc: 0.9953 - val_loss: 0.1104 - val_acc: 0.9883\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0277 - acc: 0.9951 - val_loss: 0.1146 - val_acc: 0.9881\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0280 - acc: 0.9950 - val_loss: 0.1155 - val_acc: 0.9886\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0251 - acc: 0.9954 - val_loss: 0.1112 - val_acc: 0.9880\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0254 - acc: 0.9953 - val_loss: 0.1110 - val_acc: 0.9880\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0253 - acc: 0.9959 - val_loss: 0.1104 - val_acc: 0.9879\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0242 - acc: 0.9957 - val_loss: 0.1106 - val_acc: 0.9879\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0263 - acc: 0.9954 - val_loss: 0.1104 - val_acc: 0.9881\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0266 - acc: 0.9955 - val_loss: 0.1101 - val_acc: 0.9881\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0259 - acc: 0.9957 - val_loss: 0.1103 - val_acc: 0.9882\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0260 - acc: 0.9954 - val_loss: 0.1102 - val_acc: 0.9881\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0248 - acc: 0.9958 - val_loss: 0.1104 - val_acc: 0.9880\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0260 - acc: 0.9957 - val_loss: 0.1106 - val_acc: 0.9880\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0263 - acc: 0.9952 - val_loss: 0.1107 - val_acc: 0.9881\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0254 - acc: 0.9953 - val_loss: 0.1107 - val_acc: 0.9881\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0256 - acc: 0.9956 - val_loss: 0.1107 - val_acc: 0.9881\n",
      "Test loss: 0.11067138006505997\n",
      "Test accuracy: 0.9881\n",
      "Remaining time: 6 days 14 hours 46 minutes 37 seconds\n",
      "Training for activation SeLU with optimizer adam\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.2456 - acc: 0.9264 - val_loss: 0.1047 - val_acc: 0.9754\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.1250 - acc: 0.9693 - val_loss: 0.1050 - val_acc: 0.9787\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1227 - acc: 0.9733 - val_loss: 0.1257 - val_acc: 0.9788\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1240 - acc: 0.9755 - val_loss: 0.1519 - val_acc: 0.9802\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.1183 - acc: 0.9788 - val_loss: 0.1386 - val_acc: 0.9824\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.1168 - acc: 0.9808 - val_loss: 0.1757 - val_acc: 0.9794\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1129 - acc: 0.9828 - val_loss: 0.1475 - val_acc: 0.9831\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1081 - acc: 0.9839 - val_loss: 0.1614 - val_acc: 0.9823\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1049 - acc: 0.9850 - val_loss: 0.1652 - val_acc: 0.9839\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1025 - acc: 0.9858 - val_loss: 0.1912 - val_acc: 0.9816\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1059 - acc: 0.9865 - val_loss: 0.1951 - val_acc: 0.9817\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1020 - acc: 0.9877 - val_loss: 0.1638 - val_acc: 0.9852\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0998 - acc: 0.9875 - val_loss: 0.1722 - val_acc: 0.9839\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1043 - acc: 0.9877 - val_loss: 0.1904 - val_acc: 0.9830\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0968 - acc: 0.9888 - val_loss: 0.1740 - val_acc: 0.9850\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0929 - acc: 0.9901 - val_loss: 0.1701 - val_acc: 0.9861\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0945 - acc: 0.9895 - val_loss: 0.2075 - val_acc: 0.9827\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0957 - acc: 0.9898 - val_loss: 0.1649 - val_acc: 0.9868\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0933 - acc: 0.9908 - val_loss: 0.1795 - val_acc: 0.9853\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0858 - acc: 0.9915 - val_loss: 0.2029 - val_acc: 0.9838\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0894 - acc: 0.9907 - val_loss: 0.1943 - val_acc: 0.9841\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0915 - acc: 0.9908 - val_loss: 0.1619 - val_acc: 0.9871\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0856 - acc: 0.9913 - val_loss: 0.1640 - val_acc: 0.9869\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0889 - acc: 0.9913 - val_loss: 0.1776 - val_acc: 0.9861\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0869 - acc: 0.9916 - val_loss: 0.1789 - val_acc: 0.9861\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0863 - acc: 0.9919 - val_loss: 0.1664 - val_acc: 0.9873\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0779 - acc: 0.9926 - val_loss: 0.1843 - val_acc: 0.9856\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0892 - acc: 0.9918 - val_loss: 0.1884 - val_acc: 0.9858\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0787 - acc: 0.9930 - val_loss: 0.2104 - val_acc: 0.9846\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0918 - acc: 0.9913 - val_loss: 0.2119 - val_acc: 0.9842\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0600 - acc: 0.9947 - val_loss: 0.1720 - val_acc: 0.9874\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0424 - acc: 0.9960 - val_loss: 0.1739 - val_acc: 0.9873\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0351 - acc: 0.9967 - val_loss: 0.1715 - val_acc: 0.9876\n",
      "Epoch 34/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0346 - acc: 0.9969 - val_loss: 0.1699 - val_acc: 0.9877\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0323 - acc: 0.9971 - val_loss: 0.1748 - val_acc: 0.9874\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0316 - acc: 0.9971 - val_loss: 0.1664 - val_acc: 0.9876\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0309 - acc: 0.9971 - val_loss: 0.1684 - val_acc: 0.9877\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0266 - acc: 0.9977 - val_loss: 0.1622 - val_acc: 0.9883\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0249 - acc: 0.9977 - val_loss: 0.1621 - val_acc: 0.9877\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0246 - acc: 0.9976 - val_loss: 0.1676 - val_acc: 0.9878\n",
      "Test loss: 0.16756786854205735\n",
      "Test accuracy: 0.9878\n",
      "Remaining time: 6 days 11 hours 59 minutes 25 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.2450 - acc: 0.9279 - val_loss: 0.1385 - val_acc: 0.9694\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1297 - acc: 0.9684 - val_loss: 0.1090 - val_acc: 0.9796\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.1208 - acc: 0.9734 - val_loss: 0.1348 - val_acc: 0.9798\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 256s 4ms/step - loss: 0.1181 - acc: 0.9767 - val_loss: 0.1215 - val_acc: 0.9827\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 278s 5ms/step - loss: 0.1207 - acc: 0.9789 - val_loss: 0.1480 - val_acc: 0.9828\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 258s 4ms/step - loss: 0.1182 - acc: 0.9805 - val_loss: 0.1322 - val_acc: 0.9838\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 274s 5ms/step - loss: 0.1076 - acc: 0.9829 - val_loss: 0.1678 - val_acc: 0.9813\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 246s 4ms/step - loss: 0.1100 - acc: 0.9840 - val_loss: 0.1583 - val_acc: 0.9827\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 259s 4ms/step - loss: 0.1008 - acc: 0.9852 - val_loss: 0.2029 - val_acc: 0.9789\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0960 - acc: 0.9859 - val_loss: 0.1663 - val_acc: 0.9839\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 264s 4ms/step - loss: 0.0574 - acc: 0.9917 - val_loss: 0.1331 - val_acc: 0.9870\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.0466 - acc: 0.9928 - val_loss: 0.1142 - val_acc: 0.9878\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0416 - acc: 0.9936 - val_loss: 0.1180 - val_acc: 0.9883\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 283s 5ms/step - loss: 0.0386 - acc: 0.9939 - val_loss: 0.1309 - val_acc: 0.9871\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 261s 4ms/step - loss: 0.0355 - acc: 0.9938 - val_loss: 0.1225 - val_acc: 0.9877\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 266s 4ms/step - loss: 0.0335 - acc: 0.9942 - val_loss: 0.1107 - val_acc: 0.9883\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 271s 5ms/step - loss: 0.0313 - acc: 0.9946 - val_loss: 0.1189 - val_acc: 0.9870\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0257 - acc: 0.9958 - val_loss: 0.1140 - val_acc: 0.9879\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0260 - acc: 0.9957 - val_loss: 0.1089 - val_acc: 0.9879\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 898s 15ms/step - loss: 0.0250 - acc: 0.9959 - val_loss: 0.1100 - val_acc: 0.9882\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0228 - acc: 0.9961 - val_loss: 0.1108 - val_acc: 0.9883\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 274s 5ms/step - loss: 0.0219 - acc: 0.9963 - val_loss: 0.1098 - val_acc: 0.9882\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 273s 5ms/step - loss: 0.0205 - acc: 0.9965 - val_loss: 0.1081 - val_acc: 0.9883\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 283s 5ms/step - loss: 0.0203 - acc: 0.9964 - val_loss: 0.1072 - val_acc: 0.9885\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 275s 5ms/step - loss: 0.0199 - acc: 0.9968 - val_loss: 0.1058 - val_acc: 0.9887\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 285s 5ms/step - loss: 0.0208 - acc: 0.9965 - val_loss: 0.1079 - val_acc: 0.9883\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 278s 5ms/step - loss: 0.0224 - acc: 0.9964 - val_loss: 0.1089 - val_acc: 0.9882\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 306s 5ms/step - loss: 0.0205 - acc: 0.9967 - val_loss: 0.1066 - val_acc: 0.9887\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 274s 5ms/step - loss: 0.0214 - acc: 0.9963 - val_loss: 0.1068 - val_acc: 0.9883\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 280s 5ms/step - loss: 0.0194 - acc: 0.9967 - val_loss: 0.1065 - val_acc: 0.9885\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 254s 4ms/step - loss: 0.0200 - acc: 0.9970 - val_loss: 0.1066 - val_acc: 0.9885\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0179 - acc: 0.9969 - val_loss: 0.1068 - val_acc: 0.9882\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0215 - acc: 0.9963 - val_loss: 0.1063 - val_acc: 0.9881\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0201 - acc: 0.9963 - val_loss: 0.1064 - val_acc: 0.9883\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0206 - acc: 0.9965 - val_loss: 0.1063 - val_acc: 0.9883\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0195 - acc: 0.9965 - val_loss: 0.1064 - val_acc: 0.9883\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0202 - acc: 0.9966 - val_loss: 0.1063 - val_acc: 0.9882\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0195 - acc: 0.9965 - val_loss: 0.1062 - val_acc: 0.9881\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 241s 4ms/step - loss: 0.0196 - acc: 0.9965 - val_loss: 0.1063 - val_acc: 0.9882\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0192 - acc: 0.9967 - val_loss: 0.1062 - val_acc: 0.9882\n",
      "Test loss: 0.10624317196074234\n",
      "Test accuracy: 0.9882\n",
      "Remaining time: 6 days 15 hours 30 minutes 00 seconds\n",
      "Training for activation SeLU with optimizer sgd\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.4710 - acc: 0.8547 - val_loss: 0.2630 - val_acc: 0.9298\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.2655 - acc: 0.9207 - val_loss: 0.1903 - val_acc: 0.9492\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1829 - acc: 0.9455 - val_loss: 0.1210 - val_acc: 0.9659\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1347 - acc: 0.9597 - val_loss: 0.0959 - val_acc: 0.9731\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1095 - acc: 0.9681 - val_loss: 0.0799 - val_acc: 0.9766\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0942 - acc: 0.9714 - val_loss: 0.0677 - val_acc: 0.9789\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0837 - acc: 0.9754 - val_loss: 0.0656 - val_acc: 0.9801\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0761 - acc: 0.9773 - val_loss: 0.0608 - val_acc: 0.9818\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0700 - acc: 0.9789 - val_loss: 0.0565 - val_acc: 0.9823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0654 - acc: 0.9800 - val_loss: 0.0521 - val_acc: 0.9841\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0624 - acc: 0.9807 - val_loss: 0.0586 - val_acc: 0.9834\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0593 - acc: 0.9814 - val_loss: 0.0600 - val_acc: 0.9820\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0553 - acc: 0.9832 - val_loss: 0.0527 - val_acc: 0.9839\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0537 - acc: 0.9835 - val_loss: 0.0508 - val_acc: 0.9850\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0508 - acc: 0.9841 - val_loss: 0.0503 - val_acc: 0.9844\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0496 - acc: 0.9845 - val_loss: 0.0484 - val_acc: 0.9855\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0482 - acc: 0.9853 - val_loss: 0.0552 - val_acc: 0.9846\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0448 - acc: 0.9860 - val_loss: 0.0495 - val_acc: 0.9854\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0442 - acc: 0.9861 - val_loss: 0.0493 - val_acc: 0.9867\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0432 - acc: 0.9862 - val_loss: 0.0475 - val_acc: 0.9854\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0409 - acc: 0.9870 - val_loss: 0.0482 - val_acc: 0.9860\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0410 - acc: 0.9871 - val_loss: 0.0462 - val_acc: 0.9863\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0398 - acc: 0.9876 - val_loss: 0.0506 - val_acc: 0.9856\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0361 - acc: 0.9889 - val_loss: 0.0469 - val_acc: 0.9868\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0474 - val_acc: 0.9867\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0348 - acc: 0.9892 - val_loss: 0.0461 - val_acc: 0.9871\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0337 - acc: 0.9899 - val_loss: 0.0476 - val_acc: 0.9873\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0466 - val_acc: 0.9873\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0331 - acc: 0.9896 - val_loss: 0.0465 - val_acc: 0.9874\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0335 - acc: 0.9897 - val_loss: 0.0463 - val_acc: 0.9869\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0466 - val_acc: 0.9874\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0330 - acc: 0.9903 - val_loss: 0.0471 - val_acc: 0.9874\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0334 - acc: 0.9895 - val_loss: 0.0469 - val_acc: 0.9876\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0328 - acc: 0.9897 - val_loss: 0.0464 - val_acc: 0.9877\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0324 - acc: 0.9903 - val_loss: 0.0477 - val_acc: 0.9872\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0329 - acc: 0.9898 - val_loss: 0.0468 - val_acc: 0.9867\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0325 - acc: 0.9900 - val_loss: 0.0462 - val_acc: 0.9875\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0304 - acc: 0.9907 - val_loss: 0.0458 - val_acc: 0.9876\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0315 - acc: 0.9903 - val_loss: 0.0458 - val_acc: 0.9875\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0313 - acc: 0.9902 - val_loss: 0.0461 - val_acc: 0.9877\n",
      "Test loss: 0.04614412600668729\n",
      "Test accuracy: 0.9877\n",
      "Remaining time: 6 days 11 hours 24 minutes 47 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.4881 - acc: 0.8464 - val_loss: 0.2894 - val_acc: 0.9213\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.2745 - acc: 0.9180 - val_loss: 0.1760 - val_acc: 0.9501\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1871 - acc: 0.9442 - val_loss: 0.1201 - val_acc: 0.9663\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1370 - acc: 0.9592 - val_loss: 0.0936 - val_acc: 0.9721\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1111 - acc: 0.9673 - val_loss: 0.0782 - val_acc: 0.9779\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0953 - acc: 0.9710 - val_loss: 0.0701 - val_acc: 0.9789\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0836 - acc: 0.9751 - val_loss: 0.0635 - val_acc: 0.9799\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0768 - acc: 0.9775 - val_loss: 0.0625 - val_acc: 0.9803\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0707 - acc: 0.9782 - val_loss: 0.0590 - val_acc: 0.9820\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0662 - acc: 0.9800 - val_loss: 0.0594 - val_acc: 0.9820\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0612 - acc: 0.9811 - val_loss: 0.0597 - val_acc: 0.9811\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0596 - acc: 0.9819 - val_loss: 0.0545 - val_acc: 0.9841\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0556 - acc: 0.9828 - val_loss: 0.0573 - val_acc: 0.9830\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0549 - acc: 0.9831 - val_loss: 0.0516 - val_acc: 0.9841\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0516 - acc: 0.9840 - val_loss: 0.0504 - val_acc: 0.9852\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0500 - acc: 0.9843 - val_loss: 0.0498 - val_acc: 0.9854\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0490 - acc: 0.9844 - val_loss: 0.0491 - val_acc: 0.9852\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0462 - acc: 0.9857 - val_loss: 0.0503 - val_acc: 0.9852\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0455 - acc: 0.9856 - val_loss: 0.0528 - val_acc: 0.9859\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0430 - acc: 0.9864 - val_loss: 0.0487 - val_acc: 0.9857\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0424 - acc: 0.9869 - val_loss: 0.0501 - val_acc: 0.9857\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0411 - acc: 0.9868 - val_loss: 0.0538 - val_acc: 0.9848\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0407 - acc: 0.9880 - val_loss: 0.0508 - val_acc: 0.9851\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0356 - acc: 0.9887 - val_loss: 0.0476 - val_acc: 0.9864\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0356 - acc: 0.9889 - val_loss: 0.0467 - val_acc: 0.9858\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0354 - acc: 0.9892 - val_loss: 0.0472 - val_acc: 0.9864\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0352 - acc: 0.9889 - val_loss: 0.0465 - val_acc: 0.9860\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0352 - acc: 0.9888 - val_loss: 0.0464 - val_acc: 0.9861\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0335 - acc: 0.9904 - val_loss: 0.0462 - val_acc: 0.9864\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0336 - acc: 0.9897 - val_loss: 0.0459 - val_acc: 0.9864\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0340 - acc: 0.9898 - val_loss: 0.0460 - val_acc: 0.9865\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0341 - acc: 0.9896 - val_loss: 0.0461 - val_acc: 0.9864\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0338 - acc: 0.9899 - val_loss: 0.0460 - val_acc: 0.9864\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0336 - acc: 0.9897 - val_loss: 0.0459 - val_acc: 0.9865\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0331 - acc: 0.9898 - val_loss: 0.0459 - val_acc: 0.9865\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0341 - acc: 0.9894 - val_loss: 0.0459 - val_acc: 0.9865\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0332 - acc: 0.9896 - val_loss: 0.0459 - val_acc: 0.9865\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0343 - acc: 0.9893 - val_loss: 0.0458 - val_acc: 0.9865\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0331 - acc: 0.9898 - val_loss: 0.0458 - val_acc: 0.9865\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0337 - acc: 0.9899 - val_loss: 0.0458 - val_acc: 0.9864\n",
      "Test loss: 0.04582397926066915\n",
      "Test accuracy: 0.9864\n",
      "Remaining time: 6 days 7 hours 49 minutes 25 seconds\n",
      "Training for activation SeLU with optimizer Adagrad\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.2476 - acc: 0.9301 - val_loss: 0.0850 - val_acc: 0.9767\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1021 - acc: 0.9695 - val_loss: 0.0758 - val_acc: 0.9787\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0779 - acc: 0.9766 - val_loss: 0.0689 - val_acc: 0.9816\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0680 - acc: 0.9804 - val_loss: 0.0556 - val_acc: 0.9847\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0610 - acc: 0.9817 - val_loss: 0.0522 - val_acc: 0.9854\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0537 - acc: 0.9840 - val_loss: 0.0560 - val_acc: 0.9845\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0490 - acc: 0.9847 - val_loss: 0.0488 - val_acc: 0.9869\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0453 - acc: 0.9856 - val_loss: 0.0523 - val_acc: 0.9855\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0431 - acc: 0.9865 - val_loss: 0.0549 - val_acc: 0.9861\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0418 - acc: 0.9868 - val_loss: 0.0549 - val_acc: 0.9858\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0403 - acc: 0.9870 - val_loss: 0.0474 - val_acc: 0.9875\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0370 - acc: 0.9883 - val_loss: 0.0542 - val_acc: 0.9866\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0354 - acc: 0.9887 - val_loss: 0.0509 - val_acc: 0.9875\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0342 - acc: 0.9892 - val_loss: 0.0533 - val_acc: 0.9870\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0314 - acc: 0.9899 - val_loss: 0.0525 - val_acc: 0.9875\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0280 - acc: 0.9905 - val_loss: 0.0487 - val_acc: 0.9877\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0260 - acc: 0.9917 - val_loss: 0.0487 - val_acc: 0.9884\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0260 - acc: 0.9915 - val_loss: 0.0488 - val_acc: 0.9876\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0257 - acc: 0.9920 - val_loss: 0.0495 - val_acc: 0.9881\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0263 - acc: 0.9916 - val_loss: 0.0486 - val_acc: 0.9878\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0260 - acc: 0.9917 - val_loss: 0.0508 - val_acc: 0.9871\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0479 - val_acc: 0.9884\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0236 - acc: 0.9923 - val_loss: 0.0477 - val_acc: 0.9880\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0234 - acc: 0.9926 - val_loss: 0.0479 - val_acc: 0.9881\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0241 - acc: 0.9925 - val_loss: 0.0478 - val_acc: 0.9882\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0244 - acc: 0.9927 - val_loss: 0.0477 - val_acc: 0.9884\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0244 - acc: 0.9923 - val_loss: 0.0475 - val_acc: 0.9882\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0248 - acc: 0.9920 - val_loss: 0.0475 - val_acc: 0.9881\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0245 - acc: 0.9920 - val_loss: 0.0476 - val_acc: 0.9881\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0243 - acc: 0.9923 - val_loss: 0.0475 - val_acc: 0.9881\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0238 - acc: 0.9927 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0248 - acc: 0.9921 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0244 - acc: 0.9921 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0228 - acc: 0.9926 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0233 - acc: 0.9926 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0240 - acc: 0.9917 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0240 - acc: 0.9921 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0249 - acc: 0.9920 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0240 - acc: 0.9925 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0237 - acc: 0.9924 - val_loss: 0.0476 - val_acc: 0.9883\n",
      "Test loss: 0.047567814423317575\n",
      "Test accuracy: 0.9883\n",
      "Remaining time: 6 days 4 hours 30 minutes 42 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.2735 - acc: 0.9258 - val_loss: 0.1088 - val_acc: 0.9731\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.1115 - acc: 0.9675 - val_loss: 0.0763 - val_acc: 0.9803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0857 - acc: 0.9746 - val_loss: 0.0681 - val_acc: 0.9817\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0717 - acc: 0.9785 - val_loss: 0.0628 - val_acc: 0.9833\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0633 - acc: 0.9810 - val_loss: 0.0567 - val_acc: 0.9842\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0570 - acc: 0.9829 - val_loss: 0.0570 - val_acc: 0.9849\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0523 - acc: 0.9841 - val_loss: 0.0537 - val_acc: 0.9858\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0499 - acc: 0.9845 - val_loss: 0.0519 - val_acc: 0.9865\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 231s 4ms/step - loss: 0.0461 - acc: 0.9858 - val_loss: 0.0579 - val_acc: 0.9846\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0431 - acc: 0.9863 - val_loss: 0.0562 - val_acc: 0.9863\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0426 - acc: 0.9869 - val_loss: 0.0579 - val_acc: 0.9860\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0398 - acc: 0.9874 - val_loss: 0.0538 - val_acc: 0.9864\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0340 - acc: 0.9892 - val_loss: 0.0512 - val_acc: 0.9878\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0333 - acc: 0.9893 - val_loss: 0.0500 - val_acc: 0.9875\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0317 - acc: 0.9897 - val_loss: 0.0491 - val_acc: 0.9878\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0331 - acc: 0.9898 - val_loss: 0.0503 - val_acc: 0.9872\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0315 - acc: 0.9905 - val_loss: 0.0496 - val_acc: 0.9878\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0311 - acc: 0.9898 - val_loss: 0.0492 - val_acc: 0.9874\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0312 - acc: 0.9901 - val_loss: 0.0493 - val_acc: 0.9879\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0309 - acc: 0.9902 - val_loss: 0.0494 - val_acc: 0.9876\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0293 - acc: 0.9905 - val_loss: 0.0495 - val_acc: 0.9878\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0319 - acc: 0.9903 - val_loss: 0.0494 - val_acc: 0.9875\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 247s 4ms/step - loss: 0.0303 - acc: 0.9901 - val_loss: 0.0494 - val_acc: 0.9875\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 238s 4ms/step - loss: 0.0304 - acc: 0.9903 - val_loss: 0.0494 - val_acc: 0.9876\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0299 - acc: 0.9906 - val_loss: 0.0494 - val_acc: 0.9877\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0305 - acc: 0.9904 - val_loss: 0.0494 - val_acc: 0.9878\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0304 - acc: 0.9906 - val_loss: 0.0493 - val_acc: 0.9876\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0298 - acc: 0.9908 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0299 - acc: 0.9904 - val_loss: 0.0493 - val_acc: 0.9878\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0295 - acc: 0.9904 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0300 - acc: 0.9903 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0305 - acc: 0.9903 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 10647s 177ms/step - loss: 0.0310 - acc: 0.9901 - val_loss: 0.0493 - val_acc: 0.9876\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0305 - acc: 0.9907 - val_loss: 0.0493 - val_acc: 0.9877\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0305 - acc: 0.9906 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 232s 4ms/step - loss: 0.0298 - acc: 0.9906 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0304 - acc: 0.9902 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 230s 4ms/step - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0303 - acc: 0.9905 - val_loss: 0.0492 - val_acc: 0.9877\n",
      "Test loss: 0.04924459680216432\n",
      "Test accuracy: 0.9877\n",
      "Remaining time: 6 days 21 hours 18 minutes 43 seconds\n",
      "Training for activation SeLU with optimizer Adadelta\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 277s 5ms/step - loss: 0.2401 - acc: 0.9285 - val_loss: 0.0856 - val_acc: 0.9765\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 267s 4ms/step - loss: 0.1133 - acc: 0.9707 - val_loss: 0.0909 - val_acc: 0.9804\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 272s 5ms/step - loss: 0.0899 - acc: 0.9766 - val_loss: 0.1022 - val_acc: 0.9794\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 262s 4ms/step - loss: 0.0861 - acc: 0.9792 - val_loss: 0.0897 - val_acc: 0.9833\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 260s 4ms/step - loss: 0.0739 - acc: 0.9821 - val_loss: 0.1048 - val_acc: 0.9814\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 249s 4ms/step - loss: 0.0662 - acc: 0.9836 - val_loss: 0.0900 - val_acc: 0.9846\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0630 - acc: 0.9851 - val_loss: 0.0952 - val_acc: 0.9850\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0629 - acc: 0.9856 - val_loss: 0.1022 - val_acc: 0.9847\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0554 - acc: 0.9878 - val_loss: 0.1090 - val_acc: 0.9846\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0538 - acc: 0.9877 - val_loss: 0.0959 - val_acc: 0.9864\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0475 - acc: 0.9888 - val_loss: 0.1010 - val_acc: 0.9848\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0482 - acc: 0.9888 - val_loss: 0.1060 - val_acc: 0.9849\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0442 - acc: 0.9901 - val_loss: 0.1041 - val_acc: 0.9861\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0399 - acc: 0.9906 - val_loss: 0.1173 - val_acc: 0.9845\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0264 - acc: 0.9935 - val_loss: 0.0919 - val_acc: 0.9866\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0206 - acc: 0.9951 - val_loss: 0.0885 - val_acc: 0.9873\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 0.0924 - val_acc: 0.9867\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0181 - acc: 0.9957 - val_loss: 0.0950 - val_acc: 0.9869\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0161 - acc: 0.9959 - val_loss: 0.0890 - val_acc: 0.9868\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0155 - acc: 0.9961 - val_loss: 0.0885 - val_acc: 0.9874\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0160 - acc: 0.9958 - val_loss: 0.0906 - val_acc: 0.9876\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0146 - acc: 0.9962 - val_loss: 0.0928 - val_acc: 0.9872\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0157 - acc: 0.9958 - val_loss: 0.0899 - val_acc: 0.9869\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.0850 - val_acc: 0.9874\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0139 - acc: 0.9962 - val_loss: 0.0904 - val_acc: 0.9880\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0142 - acc: 0.9960 - val_loss: 0.0870 - val_acc: 0.9873\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0141 - acc: 0.9965 - val_loss: 0.0880 - val_acc: 0.9866\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0139 - acc: 0.9963 - val_loss: 0.0848 - val_acc: 0.9868\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0132 - acc: 0.9966 - val_loss: 0.0897 - val_acc: 0.9872\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0112 - acc: 0.9968 - val_loss: 0.0891 - val_acc: 0.9873\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.0881 - val_acc: 0.9872\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0097 - acc: 0.9975 - val_loss: 0.0897 - val_acc: 0.9874\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0100 - acc: 0.9972 - val_loss: 0.0898 - val_acc: 0.9870\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0115 - acc: 0.9969 - val_loss: 0.0884 - val_acc: 0.9874\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0109 - acc: 0.9971 - val_loss: 0.0879 - val_acc: 0.9872\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0103 - acc: 0.9973 - val_loss: 0.0878 - val_acc: 0.9872\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0092 - acc: 0.9976 - val_loss: 0.0880 - val_acc: 0.9872\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0096 - acc: 0.9976 - val_loss: 0.0882 - val_acc: 0.9872\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0102 - acc: 0.9974 - val_loss: 0.0883 - val_acc: 0.9871\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0101 - acc: 0.9973 - val_loss: 0.0883 - val_acc: 0.9872\n",
      "Test loss: 0.0882980914409859\n",
      "Test accuracy: 0.9872\n",
      "Remaining time: 6 days 16 hours 13 minutes 38 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2464 - acc: 0.9272 - val_loss: 0.1149 - val_acc: 0.9716\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.1165 - acc: 0.9699 - val_loss: 0.1566 - val_acc: 0.9676\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0975 - acc: 0.9754 - val_loss: 0.1043 - val_acc: 0.9794\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0866 - acc: 0.9784 - val_loss: 0.1025 - val_acc: 0.9827\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0772 - acc: 0.9816 - val_loss: 0.0906 - val_acc: 0.9835\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0693 - acc: 0.9832 - val_loss: 0.1191 - val_acc: 0.9818\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0650 - acc: 0.9847 - val_loss: 0.0880 - val_acc: 0.9862\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0629 - acc: 0.9858 - val_loss: 0.1073 - val_acc: 0.9840\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0582 - acc: 0.9867 - val_loss: 0.0992 - val_acc: 0.9856\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0546 - acc: 0.9876 - val_loss: 0.1106 - val_acc: 0.9850\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0522 - acc: 0.9883 - val_loss: 0.1079 - val_acc: 0.9859\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0330 - acc: 0.9924 - val_loss: 0.0825 - val_acc: 0.9888\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0238 - acc: 0.9939 - val_loss: 0.0864 - val_acc: 0.9885\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0239 - acc: 0.9940 - val_loss: 0.0821 - val_acc: 0.9892\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0220 - acc: 0.9944 - val_loss: 0.0790 - val_acc: 0.9890\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0194 - acc: 0.9948 - val_loss: 0.0795 - val_acc: 0.9882\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0215 - acc: 0.9947 - val_loss: 0.0832 - val_acc: 0.9881\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0183 - acc: 0.9951 - val_loss: 0.0795 - val_acc: 0.9886\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0157 - acc: 0.9956 - val_loss: 0.0791 - val_acc: 0.9890\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0151 - acc: 0.9958 - val_loss: 0.0784 - val_acc: 0.9891\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0155 - acc: 0.9960 - val_loss: 0.0783 - val_acc: 0.9889\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0151 - acc: 0.9961 - val_loss: 0.0781 - val_acc: 0.9888\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0144 - acc: 0.9961 - val_loss: 0.0774 - val_acc: 0.9889\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0147 - acc: 0.9959 - val_loss: 0.0781 - val_acc: 0.9889\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0146 - acc: 0.9966 - val_loss: 0.0784 - val_acc: 0.9888\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.0786 - val_acc: 0.9888\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0141 - acc: 0.9963 - val_loss: 0.0783 - val_acc: 0.9889\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0141 - acc: 0.9961 - val_loss: 0.0782 - val_acc: 0.9888\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0127 - acc: 0.9967 - val_loss: 0.0782 - val_acc: 0.9888\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0140 - acc: 0.9963 - val_loss: 0.0782 - val_acc: 0.9890\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.0782 - val_acc: 0.9890\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0152 - acc: 0.9957 - val_loss: 0.0782 - val_acc: 0.9891\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0150 - acc: 0.9961 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0146 - acc: 0.9962 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0137 - acc: 0.9963 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0134 - acc: 0.9961 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 37/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0148 - acc: 0.9960 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0147 - acc: 0.9963 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0132 - acc: 0.9963 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0137 - acc: 0.9961 - val_loss: 0.0783 - val_acc: 0.9891\n",
      "Test loss: 0.07825659418930768\n",
      "Test accuracy: 0.9891\n",
      "Remaining time: 6 days 11 hours 21 minutes 15 seconds\n",
      "Training for activation SeLU with optimizer Adamax\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2464 - acc: 0.9245 - val_loss: 0.1006 - val_acc: 0.9742\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.1021 - acc: 0.9703 - val_loss: 0.0774 - val_acc: 0.9809\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0809 - acc: 0.9771 - val_loss: 0.0739 - val_acc: 0.9837\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0717 - acc: 0.9798 - val_loss: 0.0782 - val_acc: 0.9817\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0650 - acc: 0.9817 - val_loss: 0.0772 - val_acc: 0.9843\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0539 - acc: 0.9849 - val_loss: 0.0807 - val_acc: 0.9834\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0530 - acc: 0.9854 - val_loss: 0.0915 - val_acc: 0.9850\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0468 - acc: 0.9866 - val_loss: 0.0811 - val_acc: 0.9853\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0465 - acc: 0.9868 - val_loss: 0.0831 - val_acc: 0.9850\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0429 - acc: 0.9880 - val_loss: 0.0858 - val_acc: 0.9850\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0387 - acc: 0.9894 - val_loss: 0.0865 - val_acc: 0.9860\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0367 - acc: 0.9899 - val_loss: 0.0944 - val_acc: 0.9856\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0321 - acc: 0.9910 - val_loss: 0.0874 - val_acc: 0.9880\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0294 - acc: 0.9913 - val_loss: 0.0989 - val_acc: 0.9857\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0329 - acc: 0.9908 - val_loss: 0.0901 - val_acc: 0.9869\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0297 - acc: 0.9920 - val_loss: 0.0887 - val_acc: 0.9871\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0257 - acc: 0.9927 - val_loss: 0.0999 - val_acc: 0.9857\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 233s 4ms/step - loss: 0.0147 - acc: 0.9954 - val_loss: 0.0889 - val_acc: 0.9880\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0889 - val_acc: 0.9869\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0135 - acc: 0.9960 - val_loss: 0.0816 - val_acc: 0.9881\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0109 - acc: 0.9963 - val_loss: 0.0821 - val_acc: 0.9882\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0109 - acc: 0.9967 - val_loss: 0.0844 - val_acc: 0.9865\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0093 - acc: 0.9968 - val_loss: 0.0788 - val_acc: 0.9878\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0826 - val_acc: 0.9881\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0092 - acc: 0.9968 - val_loss: 0.0806 - val_acc: 0.9876\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0077 - acc: 0.9977 - val_loss: 0.0801 - val_acc: 0.9879\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0079 - acc: 0.9976 - val_loss: 0.0793 - val_acc: 0.9882\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0790 - val_acc: 0.9881\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0071 - acc: 0.9977 - val_loss: 0.0798 - val_acc: 0.9883\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0076 - acc: 0.9975 - val_loss: 0.0792 - val_acc: 0.9884\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0794 - val_acc: 0.9880\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0792 - val_acc: 0.9884\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0072 - acc: 0.9975 - val_loss: 0.0794 - val_acc: 0.9883\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0084 - acc: 0.9975 - val_loss: 0.0782 - val_acc: 0.9885\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0792 - val_acc: 0.9884\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0071 - acc: 0.9975 - val_loss: 0.0798 - val_acc: 0.9880\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0793 - val_acc: 0.9879\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0068 - acc: 0.9977 - val_loss: 0.0795 - val_acc: 0.9878\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0792 - val_acc: 0.9879\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0065 - acc: 0.9978 - val_loss: 0.0795 - val_acc: 0.9877\n",
      "Test loss: 0.07948067439237748\n",
      "Test accuracy: 0.9877\n",
      "Remaining time: 6 days 6 hours 52 minutes 46 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2399 - acc: 0.9264 - val_loss: 0.0954 - val_acc: 0.9732\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1003 - acc: 0.9715 - val_loss: 0.0931 - val_acc: 0.9769\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0842 - acc: 0.9764 - val_loss: 0.0883 - val_acc: 0.9804\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0727 - acc: 0.9794 - val_loss: 0.0674 - val_acc: 0.9843\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0671 - acc: 0.9815 - val_loss: 0.1082 - val_acc: 0.9784\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0599 - acc: 0.9834 - val_loss: 0.0686 - val_acc: 0.9860\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0545 - acc: 0.9852 - val_loss: 0.0769 - val_acc: 0.9848\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0524 - acc: 0.9858 - val_loss: 0.0801 - val_acc: 0.9858\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0481 - acc: 0.9865 - val_loss: 0.0848 - val_acc: 0.9855\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 239s 4ms/step - loss: 0.0434 - acc: 0.9884 - val_loss: 0.0834 - val_acc: 0.9868\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0412 - acc: 0.9885 - val_loss: 0.0851 - val_acc: 0.9880\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0391 - acc: 0.9897 - val_loss: 0.0884 - val_acc: 0.9858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0378 - acc: 0.9900 - val_loss: 0.0901 - val_acc: 0.9872\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0325 - acc: 0.9910 - val_loss: 0.0980 - val_acc: 0.9858\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0315 - acc: 0.9915 - val_loss: 0.0923 - val_acc: 0.9869\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0180 - acc: 0.9949 - val_loss: 0.0759 - val_acc: 0.9885\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0157 - acc: 0.9955 - val_loss: 0.0749 - val_acc: 0.9890\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0144 - acc: 0.9959 - val_loss: 0.0763 - val_acc: 0.9888\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 237s 4ms/step - loss: 0.0130 - acc: 0.9961 - val_loss: 0.0718 - val_acc: 0.9890\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0762 - val_acc: 0.9887\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0117 - acc: 0.9962 - val_loss: 0.0748 - val_acc: 0.9890\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0096 - acc: 0.9970 - val_loss: 0.0718 - val_acc: 0.9892\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 260s 4ms/step - loss: 0.0102 - acc: 0.9964 - val_loss: 0.0719 - val_acc: 0.9892\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0093 - acc: 0.9969 - val_loss: 0.0713 - val_acc: 0.9888\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0097 - acc: 0.9968 - val_loss: 0.0707 - val_acc: 0.9891\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0094 - acc: 0.9968 - val_loss: 0.0731 - val_acc: 0.9894\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0098 - acc: 0.9969 - val_loss: 0.0723 - val_acc: 0.9893\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0085 - acc: 0.9972 - val_loss: 0.0721 - val_acc: 0.9892\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0086 - acc: 0.9972 - val_loss: 0.0716 - val_acc: 0.9892\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0087 - acc: 0.9968 - val_loss: 0.0715 - val_acc: 0.9893\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0082 - acc: 0.9973 - val_loss: 0.0702 - val_acc: 0.9892\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0701 - val_acc: 0.9892\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0703 - val_acc: 0.9893\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0701 - val_acc: 0.9895\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0075 - acc: 0.9976 - val_loss: 0.0703 - val_acc: 0.9895\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0704 - val_acc: 0.9895\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0703 - val_acc: 0.9894\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0086 - acc: 0.9974 - val_loss: 0.0703 - val_acc: 0.9894\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0702 - val_acc: 0.9895\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0084 - acc: 0.9972 - val_loss: 0.0702 - val_acc: 0.9895\n",
      "Test loss: 0.07019284479929001\n",
      "Test accuracy: 0.9895\n",
      "Remaining time: 6 days 2 hours 46 minutes 38 seconds\n",
      "Training for activation SeLU with optimizer Nadam\n",
      "------------------------------\n",
      "Experiment 1\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.2764 - acc: 0.9319 - val_loss: 0.2068 - val_acc: 0.9715\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2237 - acc: 0.9674 - val_loss: 0.2347 - val_acc: 0.9742\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2367 - acc: 0.9719 - val_loss: 0.2868 - val_acc: 0.9738\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2286 - acc: 0.9758 - val_loss: 0.1931 - val_acc: 0.9837\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2350 - acc: 0.9780 - val_loss: 0.2810 - val_acc: 0.9771\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2397 - acc: 0.9789 - val_loss: 0.2926 - val_acc: 0.9775\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.2414 - acc: 0.9795 - val_loss: 0.2908 - val_acc: 0.9772\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2416 - acc: 0.9809 - val_loss: 0.2732 - val_acc: 0.9806\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1689 - acc: 0.9869 - val_loss: 0.2110 - val_acc: 0.9847\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1394 - acc: 0.9889 - val_loss: 0.1775 - val_acc: 0.9862\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1197 - acc: 0.9902 - val_loss: 0.1847 - val_acc: 0.9861\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1097 - acc: 0.9907 - val_loss: 0.2031 - val_acc: 0.9854\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1104 - acc: 0.9907 - val_loss: 0.1892 - val_acc: 0.9862\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1037 - acc: 0.9913 - val_loss: 0.1689 - val_acc: 0.9871\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0924 - acc: 0.9920 - val_loss: 0.1621 - val_acc: 0.9874\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0861 - acc: 0.9928 - val_loss: 0.1623 - val_acc: 0.9872\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0827 - acc: 0.9926 - val_loss: 0.1776 - val_acc: 0.9866\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0820 - acc: 0.9929 - val_loss: 0.1617 - val_acc: 0.9880\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0798 - acc: 0.9931 - val_loss: 0.1698 - val_acc: 0.9870\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0759 - acc: 0.9934 - val_loss: 0.1602 - val_acc: 0.9877\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0800 - acc: 0.9931 - val_loss: 0.1719 - val_acc: 0.9873\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0760 - acc: 0.9938 - val_loss: 0.1550 - val_acc: 0.9877\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0620 - acc: 0.9948 - val_loss: 0.1542 - val_acc: 0.9885\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0572 - acc: 0.9951 - val_loss: 0.1566 - val_acc: 0.9882\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0561 - acc: 0.9951 - val_loss: 0.1594 - val_acc: 0.9876\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0558 - acc: 0.9953 - val_loss: 0.1549 - val_acc: 0.9880\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0522 - acc: 0.9956 - val_loss: 0.1533 - val_acc: 0.9888\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0532 - acc: 0.9955 - val_loss: 0.1501 - val_acc: 0.9884\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0514 - acc: 0.9955 - val_loss: 0.1471 - val_acc: 0.9891\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0499 - acc: 0.9958 - val_loss: 0.1495 - val_acc: 0.9885\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0495 - acc: 0.9957 - val_loss: 0.1479 - val_acc: 0.9878\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0506 - acc: 0.9955 - val_loss: 0.1491 - val_acc: 0.9879\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0475 - acc: 0.9958 - val_loss: 0.1523 - val_acc: 0.9883\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0462 - acc: 0.9960 - val_loss: 0.1478 - val_acc: 0.9886\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0484 - acc: 0.9957 - val_loss: 0.1482 - val_acc: 0.9883\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0476 - acc: 0.9959 - val_loss: 0.1477 - val_acc: 0.9881\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0466 - acc: 0.9960 - val_loss: 0.1484 - val_acc: 0.9884\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0461 - acc: 0.9962 - val_loss: 0.1463 - val_acc: 0.9882\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0446 - acc: 0.9962 - val_loss: 0.1454 - val_acc: 0.9883\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0444 - acc: 0.9961 - val_loss: 0.1450 - val_acc: 0.9885\n",
      "Test loss: 0.14503407138019966\n",
      "Test accuracy: 0.9885\n",
      "Remaining time: 5 days 22 hours 52 minutes 59 seconds\n",
      "------------------------------\n",
      "Experiment 2\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.2762 - acc: 0.9342 - val_loss: 0.2530 - val_acc: 0.9647\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2194 - acc: 0.9681 - val_loss: 0.2297 - val_acc: 0.9762\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.2327 - acc: 0.9728 - val_loss: 0.2272 - val_acc: 0.9788\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2313 - acc: 0.9761 - val_loss: 0.3316 - val_acc: 0.9718\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2326 - acc: 0.9783 - val_loss: 0.2529 - val_acc: 0.9800\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2356 - acc: 0.9793 - val_loss: 0.2680 - val_acc: 0.9797\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2319 - acc: 0.9808 - val_loss: 0.2442 - val_acc: 0.9818\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2522 - acc: 0.9802 - val_loss: 0.2335 - val_acc: 0.9838\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2458 - acc: 0.9811 - val_loss: 0.2878 - val_acc: 0.9797\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2321 - acc: 0.9824 - val_loss: 0.2555 - val_acc: 0.9811\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2522 - acc: 0.9815 - val_loss: 0.2756 - val_acc: 0.9807\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.2433 - acc: 0.9824 - val_loss: 0.2712 - val_acc: 0.9816\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1910 - acc: 0.9863 - val_loss: 0.2325 - val_acc: 0.9838\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1501 - acc: 0.9891 - val_loss: 0.2186 - val_acc: 0.9847\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1463 - acc: 0.9894 - val_loss: 0.2134 - val_acc: 0.9850\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1233 - acc: 0.9911 - val_loss: 0.2237 - val_acc: 0.9847\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1209 - acc: 0.9912 - val_loss: 0.2162 - val_acc: 0.9847\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1174 - acc: 0.9914 - val_loss: 0.1983 - val_acc: 0.9862\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.1121 - acc: 0.9917 - val_loss: 0.2165 - val_acc: 0.9852\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1145 - acc: 0.9916 - val_loss: 0.2009 - val_acc: 0.9859\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1045 - acc: 0.9926 - val_loss: 0.1991 - val_acc: 0.9862\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.1020 - acc: 0.9924 - val_loss: 0.2000 - val_acc: 0.9860\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0971 - acc: 0.9929 - val_loss: 0.1953 - val_acc: 0.9861\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0889 - acc: 0.9935 - val_loss: 0.1905 - val_acc: 0.9873\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0875 - acc: 0.9939 - val_loss: 0.1938 - val_acc: 0.9867\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0830 - acc: 0.9939 - val_loss: 0.1902 - val_acc: 0.9868\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 236s 4ms/step - loss: 0.0834 - acc: 0.9939 - val_loss: 0.1882 - val_acc: 0.9872\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0824 - acc: 0.9940 - val_loss: 0.1906 - val_acc: 0.9866\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0836 - acc: 0.9937 - val_loss: 0.1897 - val_acc: 0.9871\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0846 - acc: 0.9939 - val_loss: 0.1908 - val_acc: 0.9871\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0817 - acc: 0.9942 - val_loss: 0.1905 - val_acc: 0.9869\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0773 - acc: 0.9944 - val_loss: 0.1901 - val_acc: 0.9871\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0793 - acc: 0.9942 - val_loss: 0.1913 - val_acc: 0.9872\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0753 - acc: 0.9945 - val_loss: 0.1910 - val_acc: 0.9871\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0759 - acc: 0.9944 - val_loss: 0.1910 - val_acc: 0.9871\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0780 - acc: 0.9942 - val_loss: 0.1909 - val_acc: 0.9872\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0777 - acc: 0.9943 - val_loss: 0.1908 - val_acc: 0.9871\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.0770 - acc: 0.9942 - val_loss: 0.1908 - val_acc: 0.9871\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0764 - acc: 0.9945 - val_loss: 0.1909 - val_acc: 0.9873\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 235s 4ms/step - loss: 0.0767 - acc: 0.9944 - val_loss: 0.1909 - val_acc: 0.9872\n",
      "Test loss: 0.1908655833487454\n",
      "Test accuracy: 0.9872\n",
      "Remaining time: 5 days 19 hours 10 minutes 13 seconds\n"
     ]
    }
   ],
   "source": [
    "# start = 2\n",
    "for opt in optimizers:\n",
    "    print(\"Training for activation SeLU with optimizer \" + opt)\n",
    "    for i in range(experiments):\n",
    "        if add_final_dense:\n",
    "            model_name = 'mnist_cnn_selu_' + opt + '_' + str(epochs) + '_' +str(i + start) + '_fd'\n",
    "        else:\n",
    "            model_name = 'mnist_cnn_selu_' + opt + '_' + str(epochs) + '_' + str(i + start)\n",
    "                \n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                         activation='selu', kernel_initializer='lecun_normal',\n",
    "                         input_shape=input_shape))\n",
    "        model.add(Conv2D(64, (3, 3), activation='selu', kernel_initializer='lecun_normal'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        model.add(AlphaDropout(0.2))\n",
    "        model.add(Flatten())\n",
    "        if add_final_dense:\n",
    "            model.add(Dense(128, activation='selu', kernel_initializer='lecun_normal'))\n",
    "            model.add(AlphaDropout(0.2))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "        if opt == 'rmsp':\n",
    "            optimizer = keras.optimizers.rmsprop()                \n",
    "        elif opt == 'adam':\n",
    "            optimizer = keras.optimizers.Adam()\n",
    "        elif opt == 'sgd':\n",
    "            optimizer = keras.optimizers.SGD()\n",
    "        elif opt == 'Adagrad':\n",
    "            optimizer = keras.optimizers.Adagrad()\n",
    "        elif opt == 'Adadelta':\n",
    "            optimizer = keras.optimizers.Adadelta()\n",
    "        elif opt == 'Adamax':\n",
    "            optimizer = keras.optimizers.Adamax()\n",
    "        elif opt == 'Nadam':\n",
    "            optimizer = keras.optimizers.Nadam()\n",
    "\n",
    "\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=['accuracy'])\n",
    "        print('-'*30)\n",
    "        print('Experiment', i+1)\n",
    "\n",
    "        csv_logger = CSVLogger('./logs/%s_%d.csv' % (model_name, units), append=False, separator=';')\n",
    "        reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, verbose=0, mode='auto', epsilon=0.0001, cooldown=2, min_lr=0)\n",
    "#         tb = TensorBoard(log_dir='./tb_logs/' + model_name + '_' + str(units), histogram_freq=0, batch_size=32, write_graph=True, write_grads=False, write_images=False, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_test, y_test), callbacks=[csv_logger, reduce_lr])\n",
    "\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        model_path = os.path.join(save_dir, model_name + \".h5\")\n",
    "#         model.save(model_path)\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        t = time.time()\n",
    "        time_diff = t - start_time\n",
    "        counter +=1\n",
    "        rem_items = total_items - counter\n",
    "        total_time = round((total_items / counter) * time_diff)\n",
    "        rem_time = round(total_time - time_diff)\n",
    "        m, s = divmod(rem_time, 60)\n",
    "        h, m = divmod(m, 60)\n",
    "        d, h = divmod(h, 24)\n",
    "        print('Remaining time: %d days %d hours %02d minutes %02d seconds' % (d, h, m, s))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
